{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このノートブックではツイートデータの「活動あり」，「活動なし」への２クラス分類タスクに取り組む<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目次\n",
    "1. [基本設定](#section1)\n",
    "    - [使用ライブラリ](#section1-1)\n",
    "    - [使用データセット, 出力パス指定](#section1-2)\n",
    "    - [パラメータの設定](#section1-3)\n",
    "2. [実験的な予測](#section2)\n",
    "    - 2.1 [使用データの読み込み](#section2-1)\n",
    "    - 2.2 [使用モデル](#section2-2)\n",
    "    - 2.3 [実験に使用するデータを訓練用と評価用に分割（テストなし）](#section2-3)\n",
    "    - 2.4 [モデル学習](#section2-4)\n",
    "    - 2.5 [評価データを用いた評価](#section2-5)\n",
    "    - 2.6 [wandb終了](#section2-6)\n",
    "3. [Cross validation](#section3-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "## 1. 基本設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/is/akiyoshi-n/my-project\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1-1'></a>\n",
    "### 使用ライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from src.my_project.dataset import load_dataset_2class_classification, split_test_data, load_text_dataset, load_dataset_2class_classification_v2\n",
    "from src.my_project.train_v2 import ActClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1-2'></a>\n",
    "### 使用データセット, 出力パス指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = Path('/home/is/akiyoshi-n/my-project/data')\n",
    "# 本日の日付\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "# 出力先ディレクトリ\n",
    "output_dir = Path('/home/is/akiyoshi-n/my-project/outputs/{}'.format(timestamp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1-3'></a>\n",
    "### パラメータの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最大トークン数\n",
    "MAX_LEN = 128\n",
    "# バッチサイズ\n",
    "BATCH_SIZE = 16\n",
    "# エポック数\n",
    "NUM_EPOCHS = 100\n",
    "# 学習率\n",
    "LEARNING_RATE = 2e-5\n",
    "# Cross Validation時のFold数\n",
    "NUM_FOLDS = 5\n",
    "# 早期停止のための忍耐値\n",
    "PATIENCE = 2\n",
    "# 乱数シード\n",
    "SEED = 2023\n",
    "# クラス数\n",
    "NUM_LABELS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "## 2. 実験的な予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2-1'></a>\n",
    "### 2.1 使用データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset_2class_classification(f\"{DATASET_PATH}/act_classification_final.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2-2'></a>\n",
    "### 2.2 使用モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 東北大BERT-v3\n",
    "MODEL_NAME = 'cl-tohoku/bert-base-japanese-v3'\n",
    "Classifier_model = ActClassifier(model_name = MODEL_NAME, num_labels=NUM_LABELS, seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2-3'></a>\n",
    "### 2.3 実験に使用するデータを訓練用と評価用に分割（テストなし）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データと評価データを辞書型で抽出\n",
    "train_dataset = {\n",
    "    'texts': [data['texts'][i] for i in range(900)],\n",
    "    'labels': [data['labels'][i] for i in range(900)]\n",
    "}\n",
    "eval_dataset = {\n",
    "    'texts': [data['texts'][i] for i in range(900, 1100)],\n",
    "    'labels': [data['labels'][i] for i in range(900, 1100)]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2-4'></a>\n",
    "### 2.4 model学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Parameter 'fn_kwargs'={'tokenizer': BertJapaneseTokenizer(name_or_path='cl-tohoku/bert-base-japanese-v3', vocab_size=32768, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t3: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}, 'max_len': 128} of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32dfa09cbdb94e9db0d417d53aa0aa28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00aa368aebd42b38b187972126d3407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='95' max='1900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  95/1900 00:47 < 15:20, 1.96 it/s, Epoch 5/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.719800</td>\n",
       "      <td>0.701722</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.415584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.657400</td>\n",
       "      <td>0.659056</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.409449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.597800</td>\n",
       "      <td>0.638591</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.436364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.494300</td>\n",
       "      <td>0.650766</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.460177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>0.655998</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.558824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Classifier_model.train_model(train_dataset, eval_dataset, MAX_LEN, NUM_EPOCHS, LEARNING_RATE, BATCH_SIZE, PATIENCE, output_dir, project_name='ActClassification', run_name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421a126488e24ee5af1ad3ea2226f12d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predictメソッドで予測\n",
    "prediction = Classifier_model.predict(trainer, eval_dataset, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ActClassifier' object has no attribute 'extract_prediction_activity_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mClassifier_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_prediction_activity_data\u001b[49m(eval_dataset, prediction)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ActClassifier' object has no attribute 'extract_prediction_activity_data'"
     ]
    }
   ],
   "source": [
    "Classifier_model.extract_prediction_activity_data(eval_dataset, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'texts': ['[USR] 私も飲んでますがw\\u3000こういうのは「ついのみ」とかいうハッシュタグつけるといいんでしたっけ．',\n",
       "  'おおー！ぜひお話をうかがってみたいです！司会進行頑張って下さい！ RT [USR] おお！\\u3000RT [USR] 仙台にて東北観光のキーパーソン達に集って頂き座談会開催。第一回目なのでテーマは「東北観光を磨くには？」司会進行役なので、しゃべり過ぎないように注意しよう\\ue409',\n",
       "  '[USR] こんにちは～！わ、みられてましたか！とりあえずこれで。ほんとはもうちょっと拡大したほうがバランスいいんですけどおそれおおいのでこれでw',\n",
       "  '起きてた！バス混んでました…。今日もクソゲー頑張ってきま',\n",
       "  '奥の方がエビだと思ってグロ画像だと空目\\u3000「サンタエビ」話題に\\u3000 [URL]',\n",
       "  'とりあえずごはんごはんーーーー',\n",
       "  'こっから銀座までなんぷんかね',\n",
       "  'うわ！\\u3000エア始まってるやんwww\\u3000はい\\u3000かんぱーい！\\u3000ってラス１ですよw',\n",
       "  '仕入れなくちゃ！ RT [USR] ショコラブルワリー(サッポロ)とショコラカクテル(アサヒ) [URL]',\n",
       "  'フォローしようと思ってた人がフォローしてくれてた',\n",
       "  '[USR] きゃーーーー！！こじゅーーー！！斬り捨ててーーーー！！！ｗｗｗ',\n",
       "  '牛めし290円最強＼(^o^)／',\n",
       "  'どちらにしても、夜まで秋葉にはいるつもりだったのでだいじょぶですよー。またーり待ってるので、気をつけて来てくださいなヽ(´ー｀)ノ',\n",
       "  'あれ、しかもRetweetぼたんできとるわ。ん？何がなくなったんだ？',\n",
       "  '足湯なう[USR] #touhokutrip  [URL]',\n",
       "  'なんでこんな煙草ＴＬなのｗｗｗ',\n",
       "  '汗かくような運動してる？体と精神のバランスだから・・・私が抱きしめてあげる～ぅRT [USR] ここんとこ、睡眠の質が悪い。疲れが取れないよ…',\n",
       "  '[USR] ザッと読んでみたが，まぁこのくらいでは楽して食えてる方じゃないのかなw',\n",
       "  '映画ＴＬに嫉妬＾＾＾// いいなあはやくみたいー！ [mb]',\n",
       "  '綿アメかと思うくらい雪質が柔らかい！RT [USR] 綿あめだろ？ｗｗ RT [USR] きれい！RT [USR] 東北本線杉田駅付近にて。快晴の雪景色もまた綺麗！ #touhokutrip [URL]',\n",
       "  '[USR] TwitBirdのRTが変だから変えてくれ、と言われて変えたはず。',\n",
       "  'みすずちん！さっきのうぷ失敗してた… [URL]',\n",
       "  'マジックテープってクラレの登録商標なのか。クラレってアルパカCMのおかげで就職希望者殺到したらしいね。案外、そんなもんなのね♪',\n",
       "  \"[USR] うまいです'`ァ(*´Д｀*)'`ァ 会社の近くにあってよかった\",\n",
       "  '角をどうやってカチュにつけるか、っと… [mb]',\n",
       "  '[USR] 実写アイコンで誰だこのリア充って思ったけど変態postのおかげですぐに誰か分かりました',\n",
       "  '[USR] ごっつぁんです！ちゃんこ！',\n",
       "  '[USR] ピンは軽く圧入されておるか，あるいは開閉時の偏磨耗で段付きに減っておると思われますからな．普通ですと平行ピンポンチで下から叩いて抜きます．',\n",
       "  '[USR] まぁ…。あでも弊社の下のローソンもいれてないですね；サンクスにはある',\n",
       "  'あれ。tomblooって、Firefoxに追加する（？）機能なのかぁ。引用しかできないのかなぁ？？',\n",
       "  '「個別都市\\u3000東京」でググっても個人指導の学習塾ばかりでした。。RT [USR] ググって出ないのは深刻。池袋でやっているパフォーマンスです。「個別都市\\u3000東京」が正式。RT [USR] [USR] TLをみて、\"個別都市東京\" とquoteしてググったら0件..',\n",
       "  'ぎゃああああああ長官の書き下ろしあったああああああああてかこれはあれか、ＤＴの絵柄くさいんですがまさか参戦！？ [mb]',\n",
       "  '何、故、フォローしたし [mb]',\n",
       "  'デュラとのファーストコンタクトであるコミックスは、主人公が帝人だった。アニメも帝人ではじまって、各回それぞれ別の人がフィーチャーされてたから、帝人ベースの話だとばかり',\n",
       "  'マイピクが増えた(*´д｀*)ﾊｧﾊｧ 嬉しすぎるぅ……(*´д｀*)ﾊｧﾊｧ [m]',\n",
       "  'ナタちゃんまた規制じゃね？',\n",
       "  '＼けんしんさまぁ／ QT [USR] 上杉謙信のアイコンが欲しいお',\n",
       "  '医者行って病気わかったら弱るから医者には行かないと',\n",
       "  '犬耳っこ\\u3000316枚\\u3000狐\\u30001105枚\\u3000猫（三次含む）\\u3000764枚\\u3000兎\\u3000869枚',\n",
       "  'とーほーしんきはなぜワンピOP歌わなかったし',\n",
       "  'カフェで力説されると、ちょっと引いちゃうんだよな～。TPOてあるよね。',\n",
       "  'ローション600ｍｌ\\u3000注射器ローション60ｍｌ\\u3000後こんなの[URL]',\n",
       "  '自室が寒いので、あたたかい部屋でぬくぬくアナログ塗りしてた [URL]',\n",
       "  '弾銃フィーバロン 1コインクリア‐ニコニコ動画(9) [URL]',\n",
       "  '空白使ってるの見るとスレタイに空白をいつも思い出してしまう',\n",
       "  'いまPWDマネージャ見たら113あった… QT [USR] そもそもよく使う通販とかWebサービスとか銀行とかだけでも合わせたら30くらいはある。これらに個別にパスワード設定してかつ定期的に変えるなんて無理。なんかパスワードに代わる別なアイデアが必要な時期に来てると思う(略',\n",
       "  'さーて私もそろそろ寝ようかね\\u3000おやすみなさいー [実はショタっ子]',\n",
       "  'めおとーく聴き終わった。',\n",
       "  '今日ノー残業デーじゃん',\n",
       "  '赤岩駅の雪の積もりようを映してみた。#touhokutrip  [URL]',\n",
       "  '【DQ4】まほうのカギがある、研究室（？）が見つからないー！＞＜',\n",
       "  'FF13の召喚獣に絶望した *Tw*',\n",
       "  '[USR] 味濃い目が好きでつｗ\\u3000ごちｗ',\n",
       "  'ぽぜてぶな方たちのTLを見ても逆に凹むと言う域',\n",
       "  '本当に同感です。 RT [USR] 国が市町村が都道府県がっていろいろ言うけれど、どこからはじめても必ずはじまる。どこから止めても少なくとも一部は必ず止まる。英断ができるところがまず動けばいいのではないだろうか。責任のなすりつけあいでは何も変わらない。',\n",
       "  '中野到着。とりあえずゲーセン。その後ブロードウェイ。その後は家まで徒歩帰宅の予定。',\n",
       "  '保護wwwwww  (#kosenconf live at [URL]',\n",
       "  'TLがイズシザかシザイズかで割れているけれど、自分はシズちゃんがいればどっちでもいいよ。',\n",
       "  'あそうだ、さっきのAPIの件は私がここで喋ってもフォローしてないされてないので全くの無意味ｗｗｗＲＴもしないでね、ばれるから',\n",
       "  'お風呂いってきまーす！',\n",
       "  '[USR] あ、そんなのついてるんだ…（これでもファン）\\u3000そうかー…そんな商売かぁー。これは買うべきなのかねェ。。DVDとか…売らないもんねェ。。ハァ…。',\n",
       "  '仕事抜け。またねすかふぇごーるどぶれんど',\n",
       "  '[USR] ｆｍｆｍ･･･もうちょっとフォロワ増えてから始めるべきだったなー\\u3000参考になりましたどうもです！',\n",
       "  '[USR] Vジャンプかってきてもいいのよ・・',\n",
       "  '[USR] 兄弟wwwwルドレクしか描いてないので、是非色んな人の呟きを漁りに行って下さいね＾＾；',\n",
       "  '[USR] [URL] - まず今年最初の仕事は大掃除から始めようか･･･',\n",
       "  'ひびきあう、ねがいがいまめざめてく♪',\n",
       "  '久しぶりにドリカムを聞きたい気分になった',\n",
       "  '[USR] おや、川崎方面おおいなあ。',\n",
       "  '国際短期大学（中野区江古田）がいつの間にか綺麗になってた！！',\n",
       "  'な、なにっ！そこでターンエンド…だと…！',\n",
       "  '読書。ますます、冴えそうだ。日頃冴えないくせにwww']}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2-5'></a>\n",
    "### 2.5 評価データを用いた評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708fe74c864d49b0816f5d220e384ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5638209581375122,\n",
       " 'eval_accuracy': 0.69,\n",
       " 'eval_f1': 0.5079365079365079,\n",
       " 'eval_runtime': 0.7559,\n",
       " 'eval_samples_per_second': 264.598,\n",
       " 'eval_steps_per_second': 6.615,\n",
       " 'epoch': 7.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifier_model.evaluation(trainer, eval_dataset, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_data\n",
    "add_dataset = load_text_dataset(f\"{DATASET_PATH}/add_data_sub.txt.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'texts': ['ディズニーランドホテルなう。',\n",
       "  '舞浜地ビールなう。奈緒ちゃんの粋な計らい。',\n",
       "  'ディズニーランドホテルは仕掛けがいろいろあって面白い。喫煙所が一つしかないけど…',\n",
       "  '喫煙所は完全に隔離され、ちゃちじゃないがホテル全体のトンマナに悪影響を及ぼさない設計',\n",
       "  'レヴィ＝ストロース氏死去､ 残念だ。ご冥福を祈ります。',\n",
       "  '相反する二つの目的を同時に達成するようなルール作り。これはクリエイティブ。サッカーにおけるオフサイドのようなやつね。',\n",
       "  'やべ。いい企画おもいついったー…',\n",
       "  'バズマン、その調子だ。',\n",
       "  'ディズニーのサービスクオリティって、アタマから安心できるよね。',\n",
       "  '昨日、昔のプロフェッショナル仕事の流儀がやってて、DNAのﾅﾝﾊﾞ社長が｢仕事が人を育てる｣と頑なに言ってたけど、八割くらいそうだと思う。',\n",
       "  'バズマン、今日の進捗全部メールしといてね。',\n",
       "  'まぢで？RT伊藤直樹がGTを卒業し、wieden+kenedyの東京オフィス代表に就任しました。',\n",
       "  'いろいろ、悩むなぁ。',\n",
       "  'デスクの上の本を整理しはじめて、早2時間。。。',\n",
       "  '今月は消費が激しいが、なんとか10万貯金する。',\n",
       "  '最近、セミナー講師をやることが多く、とっても勉強になっている件。',\n",
       "  '「会食」ってコトバはやっぱりすきじゃないね。',\n",
       "  '「できること」と「できないこと」の境界線をどれだけしっているか。という点はプランナーにとって不可欠。もちろん「できる」前提で「どうすればできるか」という発想も大切なのは言うまでもないが、「境界線」を知らなければ「どうすれば・・・」という発想すら生まれないわけで。',\n",
       "  '若くして出世できる会社（この言い方、すごく違和感あるけど）は、ものすごいメリットがある反面、頭ごなしに否定してくれる人間がいないので、胃の中のなんちゃらになりがち。きちんと市場対応できるようになるためには、外に開いていないと。裸の王様になっちまう。',\n",
       "  'ガスガスっと、こう、上からグシャって感じでつぶしたい。',\n",
       "  '「代理店連結育成プログラム」ってのを代理店連結でやっているらしいのだが、代理店連結だけでやることに大して意味はないので、本部側から色々歩み寄るべきだと思う。一番でかいハブなので。専門特化している連結各社のノウハウをダイレクトに共有しても良い意味での横ストレッチにはなりにくい。',\n",
       "  'ちなみに「体で覚えたことは忘れにくい」といいつつも、しっかりとベースの弾き方等々は忘れています・・・',\n",
       "  '僕は若輩者なので比較的どんな学生とも会いたいと思っているんだけど、単純に「会う」だけってないじゃない。「出会い系」じゃないんだし、とはいえ「パートナー選び」の感覚はあるし。そういう場面は「売り込み」じゃない。',\n",
       "  'たまに「メタ」的に確認いれないと。結構、アタマの使い方に漏れがある。',\n",
       "  '仕事の質を高めるためにやることはシンプルに4つ。①重要な行動を増やす、②重要でない行動減らす、③新しい行動を追加する、④あることを完全にやめる。',\n",
       "  '「定義」とか「原理」とかを考えていくと、とても前頭葉がアツクなる。',\n",
       "  '今のYouTubeのチャンネルの構造は「見せる」よりも「見る」に適している、マイプレーヤー型であると思う。とっても使いやすい。',\n",
       "  'ホルモンとPerfumeを交互に聴きながら、たまにSex Machingunsを挟み込みつつ資料を作る。',\n",
       "  '「楽勝」の感覚が芽生え始めると、次のステージに以降する段階。「楽勝」⇒「辛勝」⇒「楽勝」⇒「辛勝」⇒「楽勝」⇒「辛勝」⇒「楽勝」⇒「辛勝」⇒「楽勝」・・・で、レベルが上がっていく。なのでそろそろ「辛勝」フェーズなオイラ。',\n",
       "  '給食食べなきゃ遊びにいけない～♪\\u3000鬼！鬼！鬼！',\n",
       "  'アンチャンのギターはホントにやばいよね。ノイジーのベースはたいしたことないけど。',\n",
       "  '意外と知られていない、アドマン元バンドマン説（笑',\n",
       "  '先週まで1ヶ月くらい新規情報摂取をほとんど止めていたんだけど（いろんな人に薦められて）、来週からまた大量情報摂取型に戻します。僕には合いませんでした。HACK型の人間なので。',\n",
       "  '「上達のスキーマ」のレベルをより高次元にもっていく。',\n",
       "  '落ち込んだ時は「ne-yoとオレは同い年」というファクトを思い出すと、良くわからず元気になれる・・・同い年かよ・・・',\n",
       "  '「ダイナミックレンジ」と「ディープジェネラリスト」。マルチ型プレーヤーとの違い。「幅の種類」と「自由度」が効く。',\n",
       "  '「スポットライトを浴び続ける人生を」「楽しい仕事を、クソ楽しく」',\n",
       "  '飲みに行きたい・・が、今夜はいろいろ全部やる。',\n",
       "  '「感覚系」と「運動系」。アウトプットベースでコネクトを強くして、トータルのレスポンススピードを上げる。たぶん、そこら辺は優れている。',\n",
       "  '「不変」と「可変」。',\n",
       "  '二項対立を相対的にする柔軟性。',\n",
       "  'たまに福山になりたいって、本気で思うよね。',\n",
       "  'デジハリの講義内容をどうするか？で、結構ドン詰まってるナウ。でも、いい意味。',\n",
       "  '今の就職活動は面白いな。僕のTwitterやブログにもガシガシメッセージやコメントが届くし、このゼロ距離感って僕の時代にはまだなかったなぁ。',\n",
       "  'う～ん。やっぱ顔が見えないと、講義ってむずかしいな。うん。',\n",
       "  '本田さん的にいうと「コントリビューション」。',\n",
       "  '結論、｢こいつ好きだわ～｣ってのが大事だと思うのだ。',\n",
       "  '｢○○は非効率的だよね｣ってフレーズは､時として格好の逃げ文句になってしまう。',\n",
       "  'オプトインとかってワードがつぶやきレベルで出ちゃうと、生活者からだいぶ離れちゃってると思う。｢生活者｣もだけど。',\n",
       "  'そういえば先ほどフォロワーが900人を突破★',\n",
       "  '最近CPAとか口にしないし、あんまり聞かなくなったなぁ。',\n",
       "  'ジャンプを買いにいく。',\n",
       "  'ジャンプと一緒に新宿スワンも購入。もちろん缶コーヒーもね★',\n",
       "  '別に相手が望まない会食ってやらないほうがいい。',\n",
       "  'ってたまに整理してみると、けっこうある。',\n",
       "  'やべぇ、白ひげがカッコよすぎるじゃねぇか（ネタばれ注意）',\n",
       "  'ダイナミックレンジというか、多芸多機能ではなく、ある種にこう対立の中でどう幅を利かせて、幅の種類を増やせるか。',\n",
       "  'やることがたくさんあったー・・・あったー・・・あったー・・・あったー・・・あったー・・・あったー・・・',\n",
       "  '＞本多先生。デジハリの資料送っておくので、確認してくんなまし★',\n",
       "  '「世界最強の男が来るぞ！」とか言われてみたい。いや「世界最高の男」と言われたい。',\n",
       "  '「朝型」がいいのはわかってるんだけど、結構「事実夜型」なオレ。「オレは夜型なんだー」と割り切りたいんだけど、「とはいえ・・・」ってハザマで悶えることってよくあるよね？',\n",
       "  '「今の仕事は、自分をどのように輝かせてくれていますか？」と、就職活動生は社員に質問してみたらいいと思う。「働かされているヒト」にこの問は答えられないから。',\n",
       "  '「奪う」という仕事の仕方は「殺伐」とするからよくないと思う。',\n",
       "  \"あ、Fit'sの応募が終わってやがる・・・\",\n",
       "  '最近エニグモさんの「プレブロ」からメール届かなくなったよね。',\n",
       "  '電車出勤はいい。大抵の人は下向いて歩いているので、上向いてあるくだけで勝者の気分★',\n",
       "  '交通情報はTwitterやね。',\n",
       "  '【ABCDの法則】当たり前のことを（A）、馬鹿にせず（B）、ちゃんと（C）やる(D）。',\n",
       "  '「僕ここまでやってるんですけど、あなたは何をやる人でしたっけ？」と言ってやりたい気持ちになることがある。',\n",
       "  'あ、今日インターンのオリエンじゃん！教えてよ人事！',\n",
       "  'さっきから広告会議さんのブログとにらめっこ。',\n",
       "  '続・インターンシップ。提案が楽しみ。使えるリソースは全部つかいましょー。',\n",
       "  'ディレクションという言葉の意味について考える。',\n",
       "  '「できる人」ってどういう人なんだろう、と改めて自問自答他問他問。自分は比較的適当な立ち居地にいるので。',\n",
       "  'セミナーが今月は五本。いやぁ～いやいやいやいや。セミナーはやる方がいい経験になる。',\n",
       "  '地獄の経費清算の巻。',\n",
       "  'さてこれからデジハリ。いい講義をしよ。',\n",
       "  '講義終了。いやぁ～､ 勉強になりました。',\n",
       "  'なんかフォロワー急増中。',\n",
       "  'バズマン、携帯の電源をONにしなさい！',\n",
       "  '今日、これ以上MTGを入れないでください。',\n",
       "  'T5改造計画、始動。',\n",
       "  'バズマンの成長速度、ハンパなくなってます。たぶん現在新卒1位。',\n",
       "  '「アカウントプランナーにもっとも必要とされるのは、広告主（クライアント）とその実施施策に対する『責任』である」',\n",
       "  'ということで、今から１０９へ撮影に。',\n",
       "  'アジェンダですら、テンション上げて作りたい。アジェンダって最初に提出するものだから、テンション高くねーとさ。ね？',\n",
       "  '最近学生からのfollowが急増。ちょっと大人になった気分（笑\\u3000これに比例して、ブログのアクセスも大学からのアクセス比率が高まった。',\n",
       "  '魅力的な人、できる人には、たくさんの「エピソード」がある。ものすごい「伝説」や「失敗談」「笑い話」が雪崩のように出てくる。「エピソードのある」人間になろう★',\n",
       "  '提案書の日本語がおかしい人がほんとに多い。まぁ、俺もだけど。',\n",
       "  'とりあえず、バズマンはがんばれるところまでがんばったので、後のフォローはオイラがいったん巻き取ります。今日は眠れんでぇ～★',\n",
       "  '「前でしゃべるのに長けている」ことと、「実務経験、実績」は必ずしも一致しない。が、「前でしゃべるのに長けている」はとても大切な能力だとも思う。',\n",
       "  '今日一日でYouTubeにいろいろ詳しくなった。というのは、多分いろんな意味で。',\n",
       "  '「横ストレッチ」を意識して実践している営業がまだまだぜんぜん少ない。個人的に、パワープレイで行こうと思う。マルチな人間になれってことじゃなく、レンジが広い人間になれってことだから、ね。',\n",
       "  '僕はリスティンガーでは現在ないが（過去リスティンガー）、リスティングを馬鹿にする人間やつまらない仕事と決め付ける人は嫌いだ。',\n",
       "  'あーなるほどね。そゆこと。',\n",
       "  'もう一回、就職活動ってやってみたい（他意はなし）。',\n",
       "  'てか、もう木曜日か。はえーなー。',\n",
       "  'もう明日は金曜日・・・って感覚がやばい。',\n",
       "  '今日はやたらとグループウェアからのアクセスが多い。何が共有されているんだろう。',\n",
       "  '一緒に同じ方向を走れない人間がいると、やっぱり滞る。なぜにネガからはいってしまうかなぁ～。リスク回避の気持ちはわからなくもないが、何もそのマインドではいいものは生み出せない。',\n",
       "  'なんつーかさー、そうじゃないじゃない。',\n",
       "  'ディレクション業務はとても大変な側面がありますが、実現までもっていくこのステップを好きになれないとね～',\n",
       "  '今のところ就職活動生に一番聞かれる質問は「なぜ今の会社を選んだんですか？」というやつ。',\n",
       "  'なぜかページの構成案を作成中。意外とこういう情報設計は得意よ、おれ。',\n",
       "  'だめだ。体調が悪い。ぐふ',\n",
       "  'なんかtaxi\\ue15aがちょー混んでるんだけど。',\n",
       "  '完全なるオバマ渋滞。',\n",
       "  '「インターネットは無法地帯」 by H',\n",
       "  '内定者たちとの飲み会終了。こんくらいフランクに飲みたいよね～★',\n",
       "  '隼氏がつぶやきだしてる。元気なら早く復帰すべし！早く～',\n",
       "  '遅くなったけど、おめでとうございます★ #ygwed',\n",
       "  '今からインターン最終プレゼン｡ 皆さん、がんばりー★',\n",
       "  'インターンいったん終了。提案レベルが高いところもあって、個人的に満足値高し。',\n",
       "  '次はアレダネ、社員vsインターン生とかも面白い。、多分、超本気でやると思う。',\n",
       "  '「有益なつぶやき」ってコトバが面白いよね。',\n",
       "  '一番乗りしてしまった',\n",
       "  'とりあえず、お疲れでした♪',\n",
       "  'うーん、体調がすこぶる悪い。',\n",
       "  'トピックスがただの共有メールになってきてるな。',\n",
       "  '今週はセミナーが3本。ちょっときつめ。',\n",
       "  'インターンの子たちから続々メールが来てる、律儀やね。',\n",
       "  '寒鰤（カンブリ）ア宮殿。',\n",
       "  'ドン・シュルツの講演。これはいくしかない。',\n",
       "  'スポットライト理論。by イケダノリユキ',\n",
       "  'ヘルシーな怒り。by 須田さん(笑)',\n",
       "  'アメーバなう、は成功すると思うけどね(立場わきまえず、客観的に、私情を介さずに冷静に、成功の定義を曖昧にしたまま語ると)',\n",
       "  '処世術。使われている方が、・・・。',\n",
       "  'お前らグチグチ言わずにかかって来いや～・・・って思う機会って、インターネットの登場で増えたよね。',\n",
       "  '簡単に言うと、肉食べたので、おなか痛い・・・',\n",
       "  'DM気づかないから、DMしたら電話してほしいｗ',\n",
       "  '「Twitterやってる人は、一般人からいかに気持ち悪いと思われているかを理解したほうがいいと思う、2chと同じ」といっている某メディアプロデューサー。僕は59％くらいアグリー。',\n",
       "  'ちなみにインフラ視点ではなく、現時点での話。',\n",
       "  'ウェブの世界は（リアルの世界とあくまで二項対立的に便宜上使うけど）リアルの影響力が持ち越される可能性が高くなってきている（数年前と比べて）。リアルでえらい人はウェブでも偉い。まぁ、そこが真価じゃないと思うけど。※ウェブでえらくて、リアルでえらくない人もいます。',\n",
       "  '僕はポケベル真拳でしたね。',\n",
       "  '決意は大事だと思う。',\n",
       "  '大学時代にエロ文化について書いた論文。やっぱり今よりあたまいい',\n",
       "  '最近、頭良さげに振る舞う学生から強気に質問されて、イライラってすることがあるが、オレはもっとひどかったんだろうな、とマヂメに反省する今日この頃。',\n",
       "  'カワムラ氏からのリプライを待っているが、意気消沈したようなので寝よう。',\n",
       "  '酔ってるのに寝れない。最悪。',\n",
       "  'おーい、みつるー。怒るよ～',\n",
       "  'アイデア脳は筋肉と一緒。鍛えなければ強くならない。',\n",
       "  'そういえば、勉強量と性欲は比例するよね。従属関係は双方向なんだろうか、一方通行なんだろうか・・・',\n",
       "  'ネガティブな質問はネガティブな回答になりやすいので、多用するべからず。',\n",
       "  'HIATUSがヤバイ件。',\n",
       "  '今日はインターン生の前でいろいろ喋ったけど、どれくらいの人が実行に移してくれるかなぁ。そこが境目。',\n",
       "  '明日のシミュレーション精度をあげると萎える。',\n",
       "  '今日はもう、がんばろう。',\n",
       "  'むちゃくちゃ寒い。めがさめる',\n",
       "  'ちなみに明日も大阪です。インターン大阪組と会食。',\n",
       "  '会食だけじゃないが楽しみである。不安は本当に行けるのか、という点。',\n",
       "  'ヌーボーはあんまり好きくない。',\n",
       "  '次から次へと～・・・',\n",
       "  '今から明日の大阪用セミナーの資料つくるぜ！',\n",
       "  'なぜペットボトルのお茶には濁りがないのか。',\n",
       "  'セミナー資料にストックができてきた。いいことだ。',\n",
       "  'あ、いいネタ思いついったー★',\n",
       "  'やべぇ、乗ってきちまった・・・',\n",
       "  '表参道なう。この後ノープロブレムで打ち合わせ。',\n",
       "  'まさかして、今日はジャンプ売ってるかんじ？',\n",
       "  '今日はトイレが近い。老人か！',\n",
       "  '大阪インターン生オモシロイ。調子に乗ってベラベラしゃべっちまった。',\n",
       "  '新幹線なう。東京帰ります!!',\n",
       "  'インターン最終ラウンド、東京インターンVS大阪インターンはホントにやったらオモシロイと思う。ここはあえてVSで(笑)',\n",
       "  '新幹線は仕事がはかどる。',\n",
       "  '白ひげーーーーーーーーー！！！',\n",
       "  '昨日の社内セミナーは反省点が多い。コトバ化、がんばろ。',\n",
       "  '「一本の映画を撮るように、人生をプロデュースしなさい」イネス・リグロン',\n",
       "  'まずは行列に並ぶこと。そして並び続けること。そうすれば誰でも先頭に立つことができる。',\n",
       "  'そう言えば、出世してある先輩から｢ついに俺に追い付いたな｣と言われ、｢とっくに追い越してるわ｣って暴言吐いてる夢を見た。',\n",
       "  'プレゼンに、銀メダルや銅メダルはない。',\n",
       "  '最近「魂の力」がキーワード。',\n",
       "  '大阪土産で買った551の豚マンが爆発しよった・・・',\n",
       "  '「プレゼンは読まずに話す。＜読む＞は解説に過ぎず、＜話す＞説得行為である」',\n",
       "  '石戸の結婚式向かうなう。',\n",
       "  '型から出ることを目指して、型にはまるべし。',\n",
       "  '東京アメリカンズクラブなう。',\n",
       "  '六本木の交差点で財布を落とした。が､ 無傷で交番に届いていました。神に感謝です。',\n",
       "  '話すことは歩くことに、書くことは走ることと似ている。歩くこと同様、長く話すことには、特別なトレーニングは比較的必要ないが､ 走ることと同様に長く書くには訓練が必要だ｡',\n",
       "  'いやあ、今日はなんか疲れましたな～。',\n",
       "  'RT もしインフルエンザが女だったら、俺をほっとかないだろうな\\u3000[押尾学]',\n",
       "  '飯がうまかった。仕事へのモチベーションが上がった。',\n",
       "  'やっぱりプレゼン資料は表紙から作る。テンション高く、芯を通すために。',\n",
       "  'セミナーやると、「自信家」という印象を持たれる。',\n",
       "  'ルフィよりも、エースよりも、白ひげになりたい、俺。',\n",
       "  '今日は、パーマをかけよう★',\n",
       "  '最近、大学生向けにセミナーやって、「ブログやってる人ー？」と「Twitterやってる人ー？」に対する回答は、ほぼ半々であることがわかった。ちなみにmixiが一番多い。',\n",
       "  'せっかくなので、ワンピースキャラクター投票開始★\\u3000ハッシュタグは、#one_piece_character',\n",
       "  'ちなみに、しつこく「サンジ」で。2位は「チョッパー」、3位は「ガイモン」ですｗ\\u3000#one_piece_character',\n",
       "  'アレなのでパーマを今からかけにいく。',\n",
       "  '広告にもサステナビリティを。',\n",
       "  '初心に戻ろう、とふと思ったが､ ちゃんとした初心が考えてみたらなかったため、改めて初心。',\n",
       "  'たまにはネガティブな感情の推進力を使う。長く使うと顔に出るが短期的にはよい弾み車になる。',\n",
       "  '一応、今日から夏休み。',\n",
       "  'なぜかアフィリエイトの提案をしている俺・・・',\n",
       "  'いかに自分中に溜め込むか？自分の中にカオスを作るか、それが問題だ。',\n",
       "  'オイラのミーティング嫌いはどうしたものか…',\n",
       "  'アイピローがとっても今ほしいの。',\n",
       "  'そう言えば、現在夏休み中。',\n",
       "  '転職サイトにいくつか登録してみた。ちなみに転職の意思はないです(笑)',\n",
       "  'プレスリリースを2本書いた。最近メキメキここら辺の能力が上がってる・・・そんなにいらんわｗ',\n",
       "  '信頼を得るまでには時間がかかるが、失うのは本当に一瞬である。ね。（俺じゃないよ）',\n",
       "  'いやぁ、俺仕事速いなぁｗｗ',\n",
       "  '今一度言おう、俺仕事早いなぁｗｗｗ',\n",
       "  '結婚式で浮くようなチャラい服が欲しい★',\n",
       "  '今電通に行くんだ～・・・ふーん。',\n",
       "  '小学校から一緒のやつが、いろいろ巡り巡って、数年遅れで広告業界A●●に。今度飲むのが楽しみ。',\n",
       "  '意外と俺よりも無礼者はたくさんいるようだ（＞＜',\n",
       "  '四週連続結婚式。本日はオイラのメンター、鷲田氏。おめでとうございます★',\n",
       "  'つたない司会でしたが、よい結婚式になって良かったです。あらためて、鷲田夫妻、おめでとうございます！ゆっくり休んでくださいな★',\n",
       "  'いや、でもマミが本当にキレイだった。うん。',\n",
       "  'RSSリーダーをすべて既読にする＝業務完了、と思わないことだ。流れに任せて眺めるべし。RSSリーダーはそういう風につかうべきもの。',\n",
       "  '「なぜあなたに仕事が来ているのですか？」を考えるべし。',\n",
       "  '今日の内藤VS亀田の試合って何時からでしたっけ？',\n",
       "  'かづ屋の餃子はうまい。',\n",
       "  '御意。RT 「右か、左か？」と聞かれたら、俺は道なき「前」を選ぶ\\u3000[押尾学]',\n",
       "  'Twitter本に出ている初心者へのススメとして「とにかくお勧めアカウントをフォローする」敵なのがあるが、あれはまったくアグリーできない。',\n",
       "  'リーダーは「No」が言える人間でなければならないし、「なぜNoなのか？」を説明できる力が必要とされる。',\n",
       "  'トイレで仕事するとはかどるよね？特に、出た瞬間はアイデアもポンと出る。。。よね？',\n",
       "  '相方の体調が悪いので、野菜たっぷりの「すいとん」を作ったが食べてくれる気配ナッシング（泣',\n",
       "  '皆さんにあまり知られていないようだが、僕はとても料理が得意です、ハイ。',\n",
       "  'ワンピース・・・第0話・・・ｗ',\n",
       "  '4月に上がる予定の総会の壇上でのスピーチが完成。いろいろと気付きがあったし、もうしゃべれる。',\n",
       "  'ちなみに今日までが夏休みであることに気がついてしまった。間違えて勤怠メール流しちゃったよ・・・',\n",
       "  'やばい、いろいろ間に合わん。。。',\n",
       "  '今からダイレクトレスポンスなミーティング泣',\n",
       "  '中目黒、五元豚なう。レッド、アズマックス、土屋が隣で飲んでるなう。',\n",
       "  'トーゴがウェブリアルに行くらしい。',\n",
       "  'わかります。by バズマン',\n",
       "  'ウェブだと流暢になる人が今日はたくさんいるなぁ～・・・オレもだけどｗ',\n",
       "  '「速さとは最高速だけではない。0→MAXへの加速力とMAX→0への減速力。すなわちアジリティ。」',\n",
       "  '午前中、激烈対応＋提案書作成20枚終了。午後は役員提案。ウシ。',\n",
       "  '最近クルマに酔いやすい。',\n",
       "  'お腹が減ったが、ここは我慢。',\n",
       "  'タカヒロさん、見つからず…',\n",
       "  'Twitterのログイン画面がカワットル！',\n",
       "  '戦略PRという言葉がミーティングで出た(笑)',\n",
       "  'キャバクラに撮影いかなきゃだな、ほんとに。',\n",
       "  '１：あなたが人生の中で最も冷や汗をかいた瞬間。血の気が引く思いをした瞬間。これを思い出す。２：そこからキーワードを単語で書き出す。３：その単語をＰＰＣ広告、キャッチコピーに使う。レターに埋め込む。従業員やメンバー全員で行い、インパクトある言葉を沢山だし、使ってください。',\n",
       "  '頑張ってる学生はオモシロイナ～★ 俺ももうちょいやれば良かったな～★',\n",
       "  'バズマンが行方不明である。',\n",
       "  '【俺が響いた就職活動心得①】「すごいヒトの含有率が高く、それらのヒトとの距離が近い会社を選ぶべし」',\n",
       "  'いったんおとなしくしよー。',\n",
       "  '月曜日はTVの収録。',\n",
       "  '改めて、ブログパワーを再構築したいと思う。そろそろアレかな・・・',\n",
       "  'タカヒロさんから頂い八つ橋が美味しい件。',\n",
       "  'バダ・ハリ vs アリスター開始！',\n",
       "  '来週は近藤しづかさんと会える。楽しみだ☆',\n",
       "  'バダ・ハリのテンションが良いカンジだ。',\n",
       "  'チャーハンを作れ、という指令が出たので、材料を買いにいく。',\n",
       "  'w-indsは韓国のアイドルみたいになってるな。',\n",
       "  '久しぶりにメガネを復活させよう。',\n",
       "  '痩せる→エンゲル係数減る→金貯まる→タワーマンションに引っ越す→モテる=仕事ができる→ハッピー。',\n",
       "  '家計簿を整理してみた。絶句する。',\n",
       "  '大阪インターン生のガシガシ質問力には恐れ入る。',\n",
       "  '現在、1人洪水状態。',\n",
       "  '学生よりも自分について考えないと。怠りがちだ。',\n",
       "  'プロモーションに定型はないんです、ってセリフはたまに格好の逃げ口上になっちまってる。',\n",
       "  '幸せな撮影だったわ～★ こんなんお金出しちゃうわ～★',\n",
       "  '一旦休憩。次は青山で打ち合わせ。東京に感謝。',\n",
       "  '次西麻布にはいつたしなみに行こう…仲間いないから、一人だな。',\n",
       "  '明日は「Amebaなう」リリース日。',\n",
       "  'twitterとAmebaなうの使い分け、どうしよー。とか考えてる時点でつぶやきではないな。',\n",
       "  'シンケンに病院に検査にいこう。',\n",
       "  'チームが逆境に立たされているとき、たったひとりの覚悟を決めた人間の一撃で状況を大逆転できる。そんな格好のケースだね、あのトピックスは。',\n",
       "  'こんばんは。アドマンの時間です。',\n",
       "  'これは禁断のツールだわぁ～・・・',\n",
       "  '久しぶりにAdwordsの管理画面をいじいじ。やはりこういうの面白かったりするｗ',\n",
       "  'あれだな。「つぶやき」ってテーマ性持たせるのがすげぇ難しいから、ブログみたいにひとりが複数のブログサービスを使い分けるとかってないな。',\n",
       "  'わかってたけどわかったのが、TwitterユーザーはAmebaなうに移行しない。それはそうだし、それでいい。',\n",
       "  '「テクノロジーはアイデアに従属する」',\n",
       "  '金ぴかの装束を身にまとった黒子になろう。',\n",
       "  '単調な作業にもクリエイティブを。',\n",
       "  '「結局、自分に不自由を課せる人が、自由を得ているのです」',\n",
       "  '「性弱説：人は生まれながらにして善良だが、弱い生き物である」',\n",
       "  '「仕事とは、喜ばれることです」',\n",
       "  '「良い組織風土を作る上で大切なのは、【上からのホウ・レン・ソウ】である。自分からのそれなしに、部下からのそれを期待してはいけない。」',\n",
       "  'となりの奴が「関西人って意外とつまんないよな」と爆弾発言をしていて、それをヒヤヒヤしながら聞いていたのは、オイラだけではないはずだ。',\n",
       "  '梨花がオイラの理想の女性だったが、崩れつつある勢いである。',\n",
       "  'なんか久しぶりにTwitterに帰ってきた感じ。とはいえ、Amebaなうでつぶやき浮気してたわけではないのだ。（つまり忙しかったということ）',\n",
       "  'とりあえず、今日から数えて100日間で18キロのダイエットを決行しようと思います。成功して、本を書きたいと思います。',\n",
       "  '日経アソシエを読んでいて「リバウンド」概念は確かにダイエットだけでなく、仕事にも活用できるな、と。',\n",
       "  'オイラの今月の目標が「穏やかになる」ことであることは、まだ誰にも気づかれていないｗ',\n",
       "  '「こころは、もっと動く。」と思って、企画を詰めよう。',\n",
       "  '高校時代の後輩が「押尾ってカッコいいっすよね！」って昔言っていたのを思い出して、これまたヒヤヒヤした。',\n",
       "  '「成長し続ける人の特徴のひとつは、【第一歩】が早いということ」',\n",
       "  '選択と集中、ってやつの大切さと難しさをわかって初めてスタートライン。そう言えば、学生時代は全くわからんかったな～★',\n",
       "  '最近｢まるくなったよね｣と言われるが、物理的なのか精神的なものなのかはっきりしない。',\n",
       "  '山手通り、ネズミ取り中。お気をつけ下さいませ。',\n",
       "  '「もし今の仕事がつまらなければ、それは仕事がつまらないのではない。あなたがつまらないのだ」',\n",
       "  '恵比寿のバカラがもう点いとる。',\n",
       "  '最近記録マニアのため、万歩計を買おうと思っている。',\n",
       "  '最近、エルレよりハイエイタスの方が好きだ。',\n",
       "  'アドワーズの管理画面をいじいじ。',\n",
       "  '受注すること「だけに」フォーカスする営業とは仕事したくない（特定の個人を指すものではありません）。',\n",
       "  'リスティングの管理画面をいじれるキャンペーンプランナーはそうはいまい・・・ｗ',\n",
       "  '眼精疲労でよく頭痛を起こすのだが、「キューピーコーワi」を飲んだら一発で治った。これ、マヂで。',\n",
       "  'ちなみに僕はコーワさんの回しもんでも、PPT（PayPerTweet）でも何でもありません。',\n",
       "  '次はもう少し高い「キューピーコーワi」を買おう。',\n",
       "  '薬を飲む時はプラシーボMAX状態に自分を暗示する。',\n",
       "  'エルレはLIVE映像を聴き流すのがいい。',\n",
       "  '腹筋５０回、腕立て５０回、ウォーキング約一時間完了。雨降ってきた。',\n",
       "  '今朝は、腹筋50回、腕立て50回、シャドー10分、ツイスト100回、柔軟5分、歩いて出社。テカテカです。目指せ18キロ減量。',\n",
       "  'マルチビタミン、マルチミネラル、ブルーベリーのサプリを購入。アサヒさんのボトルのやつ。',\n",
       "  '担々春雨＋納豆＋サプリメントで昼食をやり過ごす。お腹いっぱい、お腹いっぱい、お腹いっぱい、お腹いっぱい、お腹いっぱい、お腹いっぱい・・・速攻歯を磨いて食欲減退。',\n",
       "  'さらにキューピーコーワi投入。ｷﾀｰ',\n",
       "  '今からthe HIATUSタイム。邪魔するやつは・・・',\n",
       "  '本日も腹筋５０回、腕立て５０回、ツイスト１００回、シャドー２００回、柔軟８分完了。ダイエット開始１日目で1.1キロ減量に成功。これを１８回繰り返せば良い。なう。',\n",
       "  '今日は昼飯：春雨＋ゼリー＋ヨーグルト。とはいえ、この後会食なので、ちゃらかな。1日の食日記もつけることにしました。',\n",
       "  'なんで働いているのか、がわからんときっと辛い。それこそなんで働いてるんだろう、と。',\n",
       "  '今とっても面白い作業をやっている。',\n",
       "  '人事よりも人事について勉強しよう。',\n",
       "  '「何でも、修正するという柔軟性を前提として、まずは頭の中から出すことだ。一度頭から出せば、それは視認できる創造物となり、多角的に検証を行うことができるようになり、それにより磨きをかけるようになることだ。だからまず、頭から出すことだ。」',\n",
       "  'そういえば今日、とある学生がうちの会社に入社する夢を見た。正夢となるのかどうか・・・',\n",
       "  '僕は海外に興味はあるけど、海外進出に興味があんまりない。',\n",
       "  '「ReTweetしたのに無視されたんですけど」ってコミュニケーションはヤメテ欲しい。',\n",
       "  '「仕事を聞かれて、会社名で答えるようなやつには負けない。」',\n",
       "  '「つまんない広告をする会社は、ほぼ、つまんない。」',\n",
       "  '「First time for everything（初めて、を恐れず、楽しく、進んでやりなさい）」',\n",
       "  '「Trust is not somethingnyou have. Something you earn.（信用は、初めからあるものではない。あなたが積み重ねていくものである。」」',\n",
       "  '「印象的な服をいることは、より良い人生につながる。」',\n",
       "  '「僕の前に道はない。僕の後に道はできる。」',\n",
       "  '「あなたのヌードは、ちゃんとエッチですか？」',\n",
       "  '「イジワルとズルは、やめよう。」',\n",
       "  '「九頭神竜男が最強の男なら\\u3000坊屋春道は最高の男よ！たがが最強程度で最高に勝てるわけが\\u3000ねーだろうがあ！ 」',\n",
       "  'フォロワーが1300名を超えました★',\n",
       "  '「貧乏でも金持ちの列の一番最後に並びなさい。」',\n",
       "  '最近、5回歯磨＠1日、を日課にしている。良い。',\n",
       "  '挨拶ができんやつがおるな～',\n",
       "  '記録の習慣がレベルアップしてきた。',\n",
       "  '最近大学生からのOB訪問依頼が１通/１日ペースで来る。が、時間が取れず、申し訳ない＆全員に対応するワケにも行かないのでどうするか迷い中（迷ってないけどｗ）',\n",
       "  '「感情がすべての行動の理由である」',\n",
       "  '「質問して答える。それが考えるということ。」',\n",
       "  '「人は１日３万回以上の思考をしている」',\n",
       "  'ダイエット開始5日目でマイナス2.5キロの減量に成功。',\n",
       "  '本多さんから素敵なインビテーションが来ていたが、見過ごしとった・・・１６日・・・',\n",
       "  '久しぶりに、Yahoo!のトップを見た。',\n",
       "  'MTGがリスケになっとる。言ってよ。',\n",
       "  '自身のアウトプットの低さ、を認識せず文句を言うクリエイターほど、イラっとくるもんはない（個人攻撃ではありません）。',\n",
       "  'やっぱ恵比寿ガーデンテラスに住みたひ。',\n",
       "  '今の人、すげぇおもろい顔してた。',\n",
       "  'ビール｢東京エール｣がうまい♪',\n",
       "  'とりあえず、ダイエット1週目の成果はマイナス2.5キロで着地しそう。来週はレバレッジ賭けて3.5キロ減まで行きたい。行ける気がする～',\n",
       "  'なるほどねー。そういうふうに返してくるか～・・・主体性とか皆無だな～・・・別にいいけど。',\n",
       "  '今日は8時に起きて、2時間走って筋トレ、その後歩いて渋谷。',\n",
       "  '最近のPVは、掘り出し物的なカワイイ娘が出てるよね。見ちゃうよね。',\n",
       "  'まぁ、でも俺は近藤しづか派だけどねｗ',\n",
       "  '昨日飲みに行ったところのお姉さんが、Shu-Thang Grafixと仲がいいらしく、個人的に仲良くしたいと思った感じです。',\n",
       "  'てか指から血がめっさ出てんだけど。なぜ？',\n",
       "  '最近、女の子みたく洗顔してたりする。ちゃんと保湿。年だから。',\n",
       "  '童子－Ｔを端的に説明するには「あの\"イェー・・・\"って言う人」って言えばいいらしい★',\n",
       "  '時間とお金を記録し続けると、本気で「時は金なり」以上に思えてくる。記録は大切。もちろん体重も記録してます。',\n",
       "  'このPVの童子-Tのモジャ頭は笑いを取りに行ってるんだよね？',\n",
       "  '体重ってのは、ほんとにレコーディング（記録）すると減るね。まだ目に見えた成果歯出ていないけど、数値上は結構いい進捗。',\n",
       "  'the HIATUS「Insomnia」のPVがYouTubeから消されている。なんとなく、細見さんらしくない、とか思ったりする（本人関係ないけど。）',\n",
       "  '「肉体的な自信は、精神的な自信につながる」',\n",
       "  '会食先の表参道まであるく。徹底的にダイエット。',\n",
       "  '自分についての感覚を磨く。それすらできていなければ、自分以外に対する感覚が磨かれるわけもなく。インサイドアウト。',\n",
       "  '毎年入ってくる新卒よりも常に高い成長率を自分には課そう。',\n",
       "  '表参道なう。キレイや！住みたい!!',\n",
       "  'ADKの野口くんと飲む。彼は実は小学生の時からの付き合い。埼玉県は入間市の治安の悪さを耐えて今がある。',\n",
       "  '「創造性や革新は、実践的で、システマティックな方法で、アプローチすることができ、開発することができ、学ぶことができるということです。つまり、それは、天才の産物ではないということです。」',\n",
       "  '「世界にある、ほとんどの革新は、実際には、今あるものや、古いものをもう１度アレンジして、違った新しいものにしたものなのです。」',\n",
       "  '「人々がテレビの電源をいれるのは、番組を楽しむためであって、コマーシャルを見るためではない。」「それならば広告は、番組にとってつけられるのではなくて、番組と誘導していかなくてはいけない。ただし重要なのは、インフォマーシャルのように視聴者を退屈させないことだ。」',\n",
       "  '宣伝会議の「広告界\\u3000就職ラボ」の内容がひどいと思うのはぼくだけ？',\n",
       "  'うちの事業部の新卒の成長率はトップレベルだと思う。現状の能力でいっても、新卒レベルではないと感じる。内定者も、下手なプランナーよりも強いレベル。いい感じだ。まだまだやってもらいたいことはあるんだけどね。',\n",
       "  'ちなみに「育成」って言葉は未だに嫌いです。育ってください、自主的に。',\n",
       "  'Twitter上には、イヂワルな（笑）諸先輩方がいて、とても幸せです★（愛を込めて）\\u3000社内よりは確実に後輩力が必要ｗｗ',\n",
       "  '今日から睡眠時間もレコーティングしようと思っている。',\n",
       "  '4月から英会話学校に思っている。いろんな理由で、英会話「学校」で「4月」から。「アドマンの英語上達への道」スポンサー募集中ｗ',\n",
       "  '恵比寿ガーデンプレイスのイルミネーションはこの時間まで点いている。それは僕のために点いているんだ、と思い込むようにしてる。',\n",
       "  '明日は①２時間ランニング、②映画「ワンピース」を観る、この２つは必ず達成する。',\n",
       "  '「冒険人生は冒険から得るものもあれば、時に失うこともある。それでも、挑戦を続けなければならない時がある。冒険人生とはそういうものなのかもしれない。」',\n",
       "  'ダイエット中のアドマンに、スポンサー募集中ｗ\\u3000（ダイエット食品、サプリメント、スポーツ用品などなど）',\n",
       "  'さて、リスティングのレポートを作ろうかな・・・',\n",
       "  '他人のToDo管理、疲れるが必要だ。',\n",
       "  '努力の無いダイエットは嫌いだ。',\n",
       "  '恵比寿駅まで徒歩25分。歩いて出社。',\n",
       "  '24日を｢今日はクリスマスじゃなくね？｣とシラケる奴よりも一緒になって盛り上がってる奴の方が好き｡',\n",
       "  'メリクリ★ #merrychristmas2009',\n",
       "  '食べる量とカロリーを大幅に減らしたら、完全に糞詰り。。。ファイブミニを飲もう。',\n",
       "  '久々に電通にいく用事ができた。',\n",
       "  '人に何かしてもらったとき『すいません』じゃなく『ありがとう』って言える人間になりたいよね。',\n",
       "  '目標を設定する時は、第三者の声＝誰になんと言わせる成果を残すか、そのセリフを決める。',\n",
       "  'ニーズ（他者）とシーズ（自分の強み）のマッチング：「自分に出来ることの中で、人の役に立つことはなんだろう？」という質問。',\n",
       "  '再現性のあるスキルは「人の役に立つ」のである。',\n",
       "  '明日は10時にワイデンに行きます。',\n",
       "  'ストレスフリーとは「多くの人に感謝され、常にさわやかな気持ちでいられる」ということ。',\n",
       "  'やっぱり年末って忙しいねぇ～。ほんとに。',\n",
       "  '最近「アドマン」検索ワードからの流入が超増えてる。なんでだろ。1年前の10倍くらい。',\n",
       "  'なぜかこの聖夜にググってはいけないキーワードを検索してしまい、気分が悪いなう。',\n",
       "  '自宅クリスマスディナーが満足度高かった。',\n",
       "  '便秘に効く特効薬を誰か教えてください。。。',\n",
       "  '会食とかって、インセンティブになんのかな？',\n",
       "  '誰と行くか、によるか。',\n",
       "  '「芯」がない「マルチキャリア」に意味はない。',\n",
       "  'ネット広告（この言葉嫌いだけど）の場合、フォーマットもテクノロジーも変化というかマイナーチェンジの繰り返しなので、それに対する「習熟度の低さ」という現象は起こりうるし、業界的にジョブローテも早いので、それにまた拍車を掛けるって側面はあるとおもう。',\n",
       "  '甘やかしちゃいけないよ、甘やかしちゃ。',\n",
       "  'やっと会社に帰れる…これぞ師走！',\n",
       "  '最近、ドラッカーをよく読む。ミンツバーグやコトラーも。でもポーターの良さがまだわからん。',\n",
       "  'なんかデカイなあいつ…',\n",
       "  '営業時間中に暇そうに馬鹿笑いするのはちげーだろ。',\n",
       "  '「『人材不足』ってのは、本当に頑張っている組織だけが吐いていいセリフだ」',\n",
       "  '内藤さんの予定が空いてない・・・',\n",
       "  '人の予定見ると、働いてるか働いてないかわかるなぁ。来社ばっかの人は・・・',\n",
       "  '「広告営業力2」を買おうかどうか迷っている件。',\n",
       "  'たまには切ない気持ちになりたいよね。',\n",
       "  'いやぁ、君には負けないよ。',\n",
       "  '意外な娘に「アドマン」と言われ、若干照れるの巻。',\n",
       "  '先月の本への投資額は\\\\\\\\35,640 なり。意外と少ないな。',\n",
       "  '交際費は\\\\\\\\122,000 。これは絶対記入漏れがあるな。',\n",
       "  '食費は異様に安いな。',\n",
       "  '大阪にも事業部作りたいなぁ。',\n",
       "  '某通信会社のお偉い方から年末ご挨拶メールが喜田が、返信に困るナウ。',\n",
       "  '高級鉄板焼なう。リア充なう。',\n",
       "  'バズマンにクリスマスの奇跡が起こったらしい。',\n",
       "  'オマールエビ、テラうます★',\n",
       "  'バズマンの奇跡宣言をフォアグラ食いながら待つ。',\n",
       "  '肉がうまひ。そしてガーリックライスで締め。至福。',\n",
       "  '改めて言おう。至福。',\n",
       "  'なりすまし、ってそろそろ捕まえるべきだよ。',\n",
       "  'どうせバズマンの奇跡は予想通りだ',\n",
       "  '今日は2時間20分走った。しかし体重は減らず。',\n",
       "  '「みかん」の効用について調査中なう。',\n",
       "  '続いてヨーグルトの効用について調べるなう。',\n",
       "  '何か新しい習慣や行動を行うときは「その効用」を頭に思い浮かべながらそれをすることによって、その効果効用が数倍になる（気がする）。',\n",
       "  '備前がのろけてる件。',\n",
       "  '備前の相方ゆき氏もヒドイ（笑）',\n",
       "  '待ち合わせ場所が神社のどこかわからない…',\n",
       "  '神社の光がスポットライトのようで心地よい。',\n",
       "  '18キロ痩せたらヨシから10万いただける。',\n",
       "  'TOPICSを書こうと思ったが、妙案浮かばず。',\n",
       "  '「努力する人は希望を語り、怠ける人は不満を語る」',\n",
       "  '「ボクシングにラッキーパンチはない！！ 結果的に偶然当たったパンチにせよ、それは練習で何百何千と振った拳だ。 その拳は生きているのだ」',\n",
       "  '弊事業部、採用活動したいなう。',\n",
       "  'いやー、ま､ いいわ。',\n",
       "  'アトラスタワー中目黒に同期が行くくさいので、青山パークタワーに変更。',\n",
       "  '今日は目黒通り沿いのsacraに行く。',\n",
       "  '睡蓮花、1人で歌うとキツイ…',\n",
       "  '今年最後の外食なう。',\n",
       "  '毎日二時間走ってると、東京はどこにすんでも変わらん気がしてきた。',\n",
       "  'ザ･シティ･タワー高輪、高輪･ザ･レジデンスがテンション上がる。',\n",
       "  '代官山いいな～★ 済もうかな～★',\n",
       "  '各店舗、プレモルがバカ売れ状態。',\n",
       "  '山の下の中目黒より、山の上の代官山。',\n",
       "  'みんなが反対するような、真っ赤なマンションに注目中。いやでも、スペック高いし、住んだら住んだで「お前らしいわ・・・」と言ってもらえそうな・・・',\n",
       "  'そういえば、今日は「トロの漬け茶漬け」と「いくらの醤油漬け」を作りました。俺は天才かもしれん・・・2010年は、もっと料理の腕を鍛えよう。',\n",
       "  '明けましておめでとうございます。本年もアドマンをよろしくお願いいたします。',\n",
       "  'さっそく目黒不動で初詣を済ませて参りました。アメ横で買ったイクラを醤油漬けに､数の子を松前漬けにしてみました★',\n",
       "  '今月は２０万くらい貯金しよ。',\n",
       "  '体重はあんま減らないんだけど、体脂肪率がガシガシ下がってる。２時間ぶっ通しで走れるように鳴っている２０１０年年明け。',\n",
       "  'いやぁ、それだと目標設定あまくね？',\n",
       "  '個人的には目標200%達成以上は、一部の例外を除き、目標設定者のミスであると思います。',\n",
       "  '銀座まるかん「スリムドカン」を購入してみたｗ',\n",
       "  '家計簿をつけるのが、こんなに楽しいとは・・・「家計も把握せずに、経営数字を把握することはできない」というのは、なんとなく理解できるところまできた。',\n",
       "  'プロになればなるほど、「細かさ」への感覚が研ぎ澄まされてくる。ドラマーがスネアの張り具合を細かく聞き分けたり、画家がその色合いを細かく調整したり。そういう境地を目指したい。',\n",
       "  'ブログ「アドマン2.0」はそろそろ閉鎖な予感。',\n",
       "  '今年の目標②：体重60キロ、体脂肪率10%以下まで減量する。',\n",
       "  '3万円分の領収書をなくした・・・何とかしてくれ・・・',\n",
       "  '本日は3時間半走った。五反田→大崎タワーマンション群→高輪→麻布（十番）→溜池山王→東京タワー→神谷町→六本木一丁目（泉ガーデンで一休み）→六本木ミッドタウン3周→広尾→恵比寿→目黒→帰宅コース。',\n",
       "  '明日会議のアイデアが2個できた。今回は・・・',\n",
       "  'ちなみに僕のウォーキングのコツは、Perfumeの「Dream Fighter」を最初15分間くらいリピートして聞き、この曲のスネアの音に歩調を合わせること。スネアが入る時に「左足」が着地するように歩くと（右でも良いけど）、ちょいキツイくらいのペースで歩くリズムが出来上がります。',\n",
       "  '15分くらい同じペースで歩くと、フォームとリズムがほぼ固定され、その後すぐにいわゆる「ウォーキングハイ」な状態に突入し、2時間は歩けるようになります（これまぢで）。',\n",
       "  '「一流企業は名もない会社であった頃から、一流企業のような経営をしていたからこそ、一流企業になれたのである」大学時代に一番刺さった言葉（from E-Myth Revisited）',\n",
       "  '明日会議じゃなくて、ジギョつくだった。',\n",
       "  '今年の目標①：本を1000冊捨てる。',\n",
       "  '今年の目標③：（月並みだけど）フルマラソンを感想する。',\n",
       "  '今年の目標④：貯金200万円。',\n",
       "  '4日まで出社しないでいられる方が信じられない、という思い。',\n",
       "  '2010年はいろいろ実現して行こうと思う。',\n",
       "  '目標設定は、行動チェックシートまで落として完了、です。',\n",
       "  'ご飯をタッパーに入れて、冷凍しました。',\n",
       "  '完全な年間スケジュールリフィル、月間スケジュールリフィル、週間スケジュールリフィル、デイリースケジュールリフィルを作成した。うまく使って、うまく行ったら公開しよ。',\n",
       "  '人生で大切な質問①「今、どんな感情を持っているだろう？」：自分の感情を理解するということは、人生の中でとても大切な側面である。なぜなら感情によって行動が方向づけられているからだ。',\n",
       "  'ちなみに昨日は、35692歩歩きました。万歩計は素晴らしい見える化ツールですね。',\n",
       "  '世界一周にはあるんだろう？',\n",
       "  '埼玉県から帰ります。',\n",
       "  '「肌がきれいになったね」と3人から言われた、新年初出社日。そりゃ気ぃ使ってますからｗ',\n",
       "  '「人の欠点が気になったら、自分の器が小さいと思うべきです」',\n",
       "  'そういえば、１４００フォロワー達成★',\n",
       "  'ちょっとみんなスパムメールに引っかかりすぎｗｗ',\n",
       "  '年明け早々、バズマンのテンションが低すぎてびっくりする。',\n",
       "  '「新規性があるシステムについてデザインの初期段階でユーザ評価を行なうと、現存のインタフェースと似ていないという理由で低い評価しか得られないことがある。」',\n",
       "  '「「私はインタフェース研究におけるテストやユーザ評価はくだらないと思っている。傲慢かもしれないが、丁寧に調べなければ違いがわからないようなものはそもそも大した違いが無いのだ。」」',\n",
       "  'そういえば、ブレーンにタカヒロさんが載ってた。',\n",
       "  '1週間を日曜日に初めて、土曜日に終わるようにしたいと思う。',\n",
       "  '今月は、どこかで渋谷→ディズニーランドまで歩くor走りたいと思う（2回目）コース上通る、東急エージェンシーさん、ADKの皆さん、応援よろしくお願いしますｗ',\n",
       "  '名言・迷言が口から出まくる人間になりたい。',\n",
       "  '前にも言った気がするが、宣伝会議に知っている方が登場していることが多く、面白い。',\n",
       "  'KeyHoleTVって、苫米地英人の会社がやってんだ！知らんかった。',\n",
       "  '2日ブリに飯をくった。春雨。お腹ｲﾊﾟｲ。',\n",
       "  '新しいものを作り出すというのは一瞬の完璧さではなく、「間違いをし、修正し、学ぶ」ことの繰り返しである。（マリッサ・メイヤー）',\n",
       "  'WordPressとMovableType、どっちがいいかなぁ。それとも他の？',\n",
       "  '今週土曜に、渋谷→ディズニー間をウォークマン&ランします！',\n",
       "  '営業マンは万歩計つけるべきだと思う。一日の歩数が1万歩以下の営業は、たぶん仕事ができない。',\n",
       "  '（誤）共有主題→（正）共有手段',\n",
       "  'ちなみにうちの会社が推奨する営業像ではなく、イチ個人の意見です。ハイ。',\n",
       "  '記録の習慣は大事だけど、完璧主義になっちゃうとキツイ。管理コスト（主に時間）が馬鹿にならん。',\n",
       "  '3,4冊併読タイプですが、時間的に2冊くらいで止めようと思う。吸収率が悪くなる。',\n",
       "  'てか、今のうち経費精算しなきゃ。先月の悲劇を繰り返さないために・・・',\n",
       "  'とはいえ、社内で僕が「足で稼ぐ営業だった」なんて言ったら「違うだろ」と言われると思います。真逆に見えるタイプだと思うので。',\n",
       "  '１４０字でちゃんと語るのは難しいな。トレーニングだな。',\n",
       "  '「運命は我らを幸福にも不幸にもしない。 ただその種子を我らに提供するだけである。」',\n",
       "  '一旦帰る。歩いて帰る。',\n",
       "  '勉強になりました。あざす★',\n",
       "  'Twitterだと後輩になれる機会が多い(相対的に)｡多謝。',\n",
       "  'そういえば、ダイエット開始約３週間経過。進捗で言うと、体重4.6キロ減、体脂肪率3.4%減。ちょっと計画上芳しくないが、痩せる体にはなってきている。',\n",
       "  'ただ一企業でピンで4年の夏季採用をやっても、正直そこまで待てる学生はいないだろうな（っていうところまで考えてるはずで、そこまで考えて決断しているところがいろいろすごい）。',\n",
       "  '春雨くった。うまし★',\n",
       "  '馬場から恵比寿まで歩いて帰るのだ!!',\n",
       "  '久しぶりの本拠地歌舞伎町ワクワクo(^o^)o',\n",
       "  '着いたよ!!意外と早い。週末の渋谷→ディズニー間ウォークも楽しみや♪',\n",
       "  '昨日集まって頂いた学生の皆様、ありがとうございました＆ご協力ありがとうございました。僕は何もやってませんが、良い刺激を頂きました。また各Twitterアカウントと本人が一致してないので、よければこのTweetにReplyしてくださいな。また話しましょう★',\n",
       "  'でも共用されてTwitterやるのは、個人的になんか嫌だな。違うとおもう、って自分がSB社員だったらいうと思う。',\n",
       "  '知り合いのSB社員に聞いたら「そうなんだ」と。',\n",
       "  '社員総会の予定がサイボウズで抑えられた。俺は知ってるよ。',\n",
       "  '最近、「結婚しないんですか？」的な質問をされるが、この質問は人を選ばないといけないと思う。俺は良いけど。',\n",
       "  '「報酬は貢献に対して与えられるべきものである。単なる努力は賞賛の的にすぎない。」',\n",
       "  '「サラリーマンとは、会社に仕事をしに行く人であり、ビジネスマンとは、会社に結果を出しに行く人を指す」',\n",
       "  'ワイデンYoshiと僕以外のCA社員十名弱が出会えた今日の奇跡。',\n",
       "  'ヤバイ、大型の仕事が一気にきやがった★',\n",
       "  '昨日の伊勢原発言が意外と反応あってびっくり。',\n",
       "  '優れた者ほど間違いは多い。それだけ新しいことを試みるからである。（ドラッカー）',\n",
       "  'あ、フォロワーが1500人突破★',\n",
       "  'HootSuiteで調べてみると、僕のアカウントからのクリック総数は1日500程度。CPC50円でクリック課金型の広告やったら、すげー儲かるなｗ\\u3000なんてな。',\n",
       "  '人生とは自転車のようなものだ。倒れないようにするには走らなければならない。（アインシュタイン）',\n",
       "  'やってみせて、言って聞かせて、やらせてみて、 ほめてやらねば人は動かじ。話し合い、耳を傾け、承認し、任せてやらねば、人は育たず。やっている、姿を感謝で見守って、信頼せねば、人は実らず。（山本 五十六）',\n",
       "  '政治家が「Twitterやる時間はない！」って発言したら、「国民と対話する時間がないと言うのか！」と、半ロジック破綻なカウンターを飛ばす人がいることを想定しないといけないよね。破綻だけど、マジョリティに届くよ。',\n",
       "  '日本はうまくいく。と思うことから、日本はうまくいく。（宝島社・2010年正月広告）',\n",
       "  '昨日、W+KのYoshiさんと話してたけど、今年のTIAAは昨日のキャノンのやつだと思う。',\n",
       "  'なぜかさっきから「セイモア・ダンカン」というキーワードが頭から離れない・・・',\n",
       "  'まぁ別にどうでもいいっちゃいいんだが、あえて正直に言えば、淳になりたい。',\n",
       "  '今日は津田さんから標的が勝間さんに移ってる。',\n",
       "  '3/31にW+Kに体重を計りに行こう。６０キロだったら勝利★',\n",
       "  'モリジンが歌うまいのは反則。',\n",
       "  '参戦するメリットないけど、それは違うね。',\n",
       "  '完全に二日酔い。ディズニーまで歩くのは明日に変更。。。',\n",
       "  '今から走る。今日は自由が丘方面へ。',\n",
       "  'YTみながらTV観てる。',\n",
       "  'ひさびさの一人ビール★',\n",
       "  '会社いってからいこー。',\n",
       "  'それでは舞浜までスタート！進捗はTwitterで報告します★',\n",
       "  'ipod忘れていったん帰宅。今から行ってきます！',\n",
       "  'また渋谷まで戻るのめんどくさい。',\n",
       "  'マークシティやっと着いた。ここから。念のため無駄にハッシュタグ作っておこ♪ #wfstd',\n",
       "  '隼のつぶやきに警告。',\n",
       "  'トライバルメディアハウス前通過！ #wfstd',\n",
       "  '母校青学通過！ #wfstd',\n",
       "  '国会図書館通過！ お堀のためランナーモード入ります!!  #wfstd',\n",
       "  'ビルコム前通過！ #wfstd',\n",
       "  'ソニー・コンピュータエンターテイメントさん追加♪  #wfstd',\n",
       "  '東急エージェンシーさん､東北新社さん通過！ #wfstd',\n",
       "  'ペースあげる!!(タクシーじゃないよ) #wfstd',\n",
       "  '桜田門通過！ #wfstd',\n",
       "  'かちどき橋なう。 #wfstd',\n",
       "  '銀座の街中をラン。ちょいちょい恥ずかしい…  #wfstd',\n",
       "  '人が多くて走れない… 一応おしゃれジャージ★  #wfstd',\n",
       "  'たぶん半分は過ぎた？ #wfstd',\n",
       "  '豊洲結構きれい。#wfstd',\n",
       "  'ただいま一万七千歩。#wfstd',\n",
       "  '最終コーナーっす！ #wfstd',\n",
       "  '軽く道に迷ってる(笑) #wfstd',\n",
       "  'というか、なにをかくそう、暗い!!#wfstd',\n",
       "  'ナイキさん、スポンサーにつきませんか？ #wfstd',\n",
       "  'あと一時間半でつく予定！只今二万歩!! そして魔の湾岸道路突入!! #wfstd',\n",
       "  '浦安の文字が見えてきた！ が､ さすがに足が痛くなってキター #wfstd',\n",
       "  '湾岸道路横の草むらで若いカップルがむちゅむちゅしてるなう。 #wfstd',\n",
       "  'きっと完走して渋谷に帰れば、鈴木と成田と坂井がビールを用意してくれているはず(笑) #wfstd',\n",
       "  '葛西臨海公園の観覧車が見えてきた！ #wfstd',\n",
       "  '荒川橋、まぢ風強い… #wfstd',\n",
       "  'ゴールが近づくにつれ、足がパンパンに…つりそう… これはアレか？ スターの素質が開花してんのか？ #wfstd',\n",
       "  '葛西臨海公園前通過！ラストスパート!! #wfstd',\n",
       "  'ストレッチしながら歩く。まぢ痛し(*_*) #wfstd',\n",
       "  'そういえば、なんでオレ歩いてんだっけ？ #wfstd',\n",
       "  'あら？ まだ環七？ #wfstd',\n",
       "  '湾岸道路は殺風景過ぎる。タワーマンションのひとつもないとはどうなってんだ!? #wfstd',\n",
       "  'とはいえ、目視で東京ディズニーランドホテルを確認!! あと少し♪ #wfstd',\n",
       "  '一旦、イクスピアリでトイレ(笑) #wfstd',\n",
       "  '渋谷→ディズニー間、約四時間十分で完走&完歩!! 総歩数31589歩★ えー、みなさま、遠慮なく褒め称えてください♪ #wfstd',\n",
       "  'さてこれからどうしよう。 1500円しかないため、パーク内には入れず… #wfstd',\n",
       "  'さて買えるか!! お疲れさまでした！ 2010年、アドマンはこんなアホなことを織り混ぜながら進化したいと思います!!ありがとうございました★ #wfstd',\n",
       "  'あ､ 最後の最後で誤字… 帰ります… #wfstd',\n",
       "  'もう新木場。文明の発達しか感じない…',\n",
       "  '次はどこまで歩こうかな～★ #wfstd 埼玉県の実家とか？ 渋谷から40キロ圏内でいいとこないすかね？',\n",
       "  '足のマメがすごい。\\u3000 #wfstd',\n",
       "  'トイレ（大）でけっこう出したはずなんだけど、体重が変わってないことってあるよね？',\n",
       "  'クリーニングを出しに行きたいのだが、足がくそほど痛いｗ',\n",
       "  '今から、湯船に湯を張ってKNEIPPでゆっくり～♪\\u3000#wfstd',\n",
       "  '「何でも謝って済むことではないけれど 謝れない人間は最低だ」金パチ',\n",
       "  'ちなみに渋谷⇒ディズニー間を歩いて消費するカロリーは１６００程度です。',\n",
       "  'Twitterは日記ではない。',\n",
       "  '足の裏の皮が剥けすぎて、靴がはけない・・・',\n",
       "  '「こんばんわ」というニュースキャスターに対して「こんばんみ」と返してしまった俺。',\n",
       "  'ヒットするファストフードの3要素「たんぱく質」「脂肪」「炭水化物」',\n",
       "  '一晩寝たら、ほぼ筋肉痛が取れて、足のマメも痛くなくなった。若いね、俺。',\n",
       "  'クローズゼロ２を観よう。',\n",
       "  '「スリムドカン」を「コントレックス」で飲む。最強だろコレ★',\n",
       "  '2010年の広告会社、の中ではワイデン＋ケネディがべた褒めされています。',\n",
       "  'クローズ観ると、筋トレしたくなるよね★',\n",
       "  '久しぶりに「」働きマン読んでる。名言がいっぱい。',\n",
       "  '「面接するって、こっちも試されてるんだよね」「今まであいまいにしてた、自分の立ち居地とか考え方とかクリアにしとかないと」',\n",
       "  '目黒駅前でたくさんの新成人女性に出くわす。みんな肌キレイネ～★',\n",
       "  '熱があり、念のため病院にいきましたが、インフルエンザではありませんでした。',\n",
       "  '今日は雨が降っているので断食。',\n",
       "  '明日のMTG合計時間は5時間半。てきぱきやろう。',\n",
       "  '雨降ったので1日断食を決行したが、雨がやんだので歩いて帰った。この胃が空の状態で寝る。',\n",
       "  'なんか目黒区内ですごい火事?',\n",
       "  'うぉっ！1日で1.2キロ減量してる★',\n",
       "  'ツイッターやりながらストレッチすると柔らかくなる。長時間やるのが苦じゃなくなるから。',\n",
       "  'メールで「君」ってけっこう失礼だと思っているので、あまり使わない。',\n",
       "  'auお留守番サービスをこの半年で100回くらい聞いて、まぢで嫌いになった。',\n",
       "  '今日でおそらく-6kg達成予定。',\n",
       "  'お気に入りの学生からよい知らせが届いた。',\n",
       "  'あ、やんちゃ時代の写真があった。即消したｗ',\n",
       "  'お腹が減ったのでシジミのカップ味噌を飲む。ご満悦♪',\n",
       "  '日々の筋トレに、ジムorヨガ追加しようかな。整えるために。',\n",
       "  '名言や格言ってのは探すもんではなく、出会うもの、だということが、名言系bot見てるとよくわかる。',\n",
       "  '腹は意識的に凹ませていると凹む。',\n",
       "  'MTGの時間の押さえ方に気の使い方がにじみ出る。',\n",
       "  '完全に風邪。喉が痛すぎるので、喉ぬーるスプレーを買う。ビタミンC補給も・・・',\n",
       "  '昨日小野田商店に行ったのに体重減ってる。',\n",
       "  'お、またお気に入り学生②からうれしい報告が★',\n",
       "  '少し体調よくなってきた。',\n",
       "  'プラダを着た悪魔、をこれから観る。',\n",
       "  'ボイストレーニングに通いたい。',\n",
       "  'うーん、納得いかね。',\n",
       "  '人に「痩せたよね」って言われるようにすることは、ダイエットの成功の秘訣だと思う。',\n",
       "  'しかし風邪が治らないな。',\n",
       "  '最高を求めて～★ 終わりのない旅をするのは♪',\n",
       "  '内藤さん家前を通過。',\n",
       "  'あ､オレじゃないよ♪',\n",
       "  '小柳津家パート2通過。',\n",
       "  'ふう、大作ブログを書いてしまった。まだ公開してないけど。',\n",
       "  'エンゼルバンクってテーマ「転職」だよね？新卒採用向けになってた。',\n",
       "  '「観客の90％が寝た！」（映画「オーシャンズ」のコピー候補）',\n",
       "  '尊敬する女性の「最近のCMはお金かけて作れてないよねぇ」と言うセリフが心に残ってます。',\n",
       "  '仕事の仕方も、CPA偏重になっちゃいけないなぁ、と。',\n",
       "  '「有用の学」だけでなく、「無用の学」も学びなさい、ですな。',\n",
       "  '風邪が治らないので、ホットレモンなう。',\n",
       "  'たぶん近いうちに創作餃子ブームがくるので(根拠なし) 東京餃子番長ってサークル作りたい。',\n",
       "  'ちょこっとだけ不動産屋へ｡やっぱあそこだなぁ～★',\n",
       "  'アドバタフライからサービス終了の連絡がきた。',\n",
       "  'ちなみに僕は卒業単位ジャストで卒業しました。',\n",
       "  'なんとかなるもんです、卒業は。',\n",
       "  '久々にブログ更新したけど、やっぱりRSSと検索からのリュ入が一番多いな～。Twitterからは200程度。',\n",
       "  '今日はアボカド。毎日食いたい。アボカドラブ。',\n",
       "  '鼻水ですらダイエットに繋げたい。量的には行けそうだ(笑)',\n",
       "  '勝負パンツが欲しい。',\n",
       "  'アメーバメンテナンスなう。',\n",
       "  'お釜のご飯をパックに入れて冷凍保存した。なう。',\n",
       "  '本を借りる感覚がイマイチわかんない。',\n",
       "  '「ひねり」系の運動をやると、快便が促進される。',\n",
       "  'ん？アメーバの管理画面がなんかおかしいぞ？',\n",
       "  '営業が提案活動を止めているとき、理由をきちんと探らないと行けない。スタッフが空気読めてないのか、ただ単に忙しいだけなのか、それもと忙しいフリをしているからなのか。',\n",
       "  'いやぁ、何を隠そう、今日は快便。',\n",
       "  'そろそろ広告系総会の時期…',\n",
       "  '今年の裏目標①：上司を立てる。',\n",
       "  'この時期から学生からのOB訪問（厳密にはOBじゃないけど）が増えてくる。去年はブログからが多かったけど、今年はTwitterと五分五分くらいだな。',\n",
       "  'DMで陰口たたくな～',\n",
       "  '何気に今日も断食中。ここまでくると、腹が減らなくなる。',\n",
       "  'なぜ誤字脱字が多いのだろう？',\n",
       "  'なんで今日はナニも食ってないのに、こんなにも快便なのだろうか・・・',\n",
       "  'ｻｲｷﾝﾉｼﾞｮｼﾀﾞｲｾｲｯﾃｵﾓｼﾛｲｶﾀｶﾞｵｵｲﾃﾞｽﾈ★\\u300027ｻｲﾉｵｯｻﾝﾊﾂｲﾃｲｹﾅｲﾄｺﾛｶﾞｱﾘﾏｽｗ',\n",
       "  '「一人より十人の方が強いのは綱引きである。発想とは、一人の頭が、十人よりも強い力を出す技術を言う。」',\n",
       "  '一旦ここらで今日のつぶやきをおわりにします。',\n",
       "  '女性にウケるアドマンを目指そ(笑)',\n",
       "  '会社から中目黒まで歩いて10分で着いた。速度上がってんな♪',\n",
       "  '昨日今日で1.5キロ減った｡ ベルトの穴がひとつ細くなった♪',\n",
       "  'たぶんこの減量ペースはあと五キロくらいで止まるので、そこからが勝負だな。',\n",
       "  '最近、若作りの32歳と言われる27歳は私のことです。',\n",
       "  '今から幕張に向かう。小旅行。',\n",
       "  'めっちゃ｢私、胸大きいですけど｣的な女性がめっちゃ谷間を強調する服着ててこれ見よがしな感じでイラッとした★',\n",
       "  '須田さん出版パーティー二次会。メンバー濃すぎて最年少アドマンは恐縮中…',\n",
       "  'きっとタナカさんはしゃべり過ぎ(笑)',\n",
       "  '僕は今の立ち位置をとっても感謝すると同時に、やっぱりいろいろ頑張らんとな、と思わせてくれる会でした。ありがとうございました★',\n",
       "  'オッサンホイホイ、マネタイズできないかな・・・',\n",
       "  '今日は結構食べたけど、渋谷から歩いて帰ったら、なんとかステイ!',\n",
       "  '久々に角の立つブログを書いている。',\n",
       "  'そういえば1年目の頃は、喫煙所でタバコ吸ってるときに、他のフロアの他の会社の女性社員に話しかけられたりしたのになぁ（過去の栄光）・・・枯れてきとる・・・',\n",
       "  '「地位とは、部下の人生に責任をもつことにほかならない」',\n",
       "  'そうだ、日サロ行こう。',\n",
       "  'やっぱ、ブログは好きだなぁ～★',\n",
       "  '事業戦略頭が欲しい。',\n",
       "  '最近「いやー残念だわ」って思う時がある。',\n",
       "  '不死鳥やらなんやらで、ワンピースの「悪魔の実」がすでに悪魔じゃなくなってる件。',\n",
       "  'たまに「Twitter革命」と「Twitter社会論」を間違えて手にとる。「革命」は神田さんなのに。',\n",
       "  '「無言のRT」という文化。',\n",
       "  'たまーに、ひとりになりたひ。',\n",
       "  'いつ会社を首になっても全然やっていけるくらいまで自分を高めながらその組織で働かないと、その組織できちんとした結果は出せない。',\n",
       "  'ということで、一部の制止を振り切って、日サロマシーンに30分ほど行ってくる★',\n",
       "  'そういえば、会社の後輩がアドマンのダイエット記事を参考にしてくれているらしいｗ',\n",
       "  '忙しくて今日何も食べてない、ってのと、戦略的に食べてないのとでは、天と地ほどの差がある',\n",
       "  'やべ！財布会社に忘れた！',\n",
       "  '店員に聞いたところ、日サロは客が激減してるそうな。',\n",
       "  'なんか弊事業部、他の部署からライバル視されてるらしい(笑) 敵視ではなく。',\n",
       "  'それでは、おやすみなさい、世界！',\n",
       "  '三時間ラン完了。日サロ効果もあってか、体が引き締まって来てるように見える。',\n",
       "  'さて、今からラン。東京タワーまで走ろう。2時間くらいかな。',\n",
       "  'アメーバなうがサービス的に被るのはアメブロよりピグだと思う。ピグもオープンな同期コミュニケーションで、実は今のところピグのほうがTwitter的コミュニケーションが成り立ってる。しかも主婦層で。またピグはまったくもってアーカイブ概念がないので、より刹那的。さてさてどうするか。',\n",
       "  '「埼玉県入間市の中学3年生が爆弾を仕掛けたとHPに書き込んだ」だと！オイラの地元やん!!母校・東町中学校でないことを祈るが、可能性高いな・・・',\n",
       "  '歩くときはヘルシアウォーター、走るときはVAAM。',\n",
       "  '今月中に60キロ台に突入したいのだが、最後の1キロがなかなか遠い。ということで、行ってきます！',\n",
       "  '走って、今アボガド切ってゴマだれと春雨と和えて食った。うまし。',\n",
       "  'そういえば、御殿山付近を走っているときに、シビル・アビディとすれ違った気がしたのだが・・・たぶん気のせいだ。',\n",
       "  'そういえば「スリムドカン」が無くなったので、追加発注せねば！',\n",
       "  'さて仕事しにいこー。',\n",
       "  'あ! 万歩計忘れた(￣▽￣;)',\n",
       "  '「君は結局何になりたいんだい？」と聞かれて「スターになりたいんです」と答えた僕は、きっと広告マンに向いてない。',\n",
       "  'いや、スクープやわ。',\n",
       "  '赤西くんってあんま好きじゃないんだよなぁ。',\n",
       "  'イケメンは好きだが、かわいげのないイケメンは好きじゃない。',\n",
       "  '彼女がいたとしても、僕は「モテたい」タイプです。ポジティブな意味で。',\n",
       "  'あ、hayabusamuraiの奥様にフォローされたようだ★',\n",
       "  '「オンステージなう」はポジティブなウェブの使い方な気がする。',\n",
       "  '前回の「渡邊エージェンシー」案が、いとも簡単に却下されたので、今度こそ！',\n",
       "  'あと数時間で給料日ですが、今月は15万ほど貯金できそうです☆',\n",
       "  'ダイエットと貯金は両輪です。',\n",
       "  'あ、やべ。家計簿付け忘れがある。',\n",
       "  '何年も経ってもさぁ～♪',\n",
       "  '芸能界デビューしたい(笑)',\n",
       "  '「朝会社に来たらすぐトイレ族」に僕のペースは乱される。',\n",
       "  'Hootsuiteは今後どう展開するんだろう？興味アリ。',\n",
       "  'なに？まだ給与明細がないだと？',\n",
       "  'ウチの会社の社員ブログで上司について触れるときに、よく会社での呼び方でそのまま書いている人がいるが、アレ、なんか恥ずかしい。外部に発信してるんだからさ・・・って思ったりする。',\n",
       "  'これからは、サイト構築中でも「工事中」ではなく「工事なう」とすればいい。',\n",
       "  '真面目なダイエッターからすると、ブログ上のクチコミより、クチコミサイト（ソーシャルレイティング）の「みんなの声」の方が参考にしてしまう。',\n",
       "  'adman.tvドメインを取得しました。',\n",
       "  'コメントしにくいニュースがあるなぁ～',\n",
       "  'そういえば今日は夢で、必死こいて「嵐」の楽曲を振りつきで練習している自分を発見してしまった。夢だよ、夢ｗ\\u3000嵐なんてほぼ踊れるからｗ',\n",
       "  '今月はめっちゃ貯金する。',\n",
       "  '明日はきっと、7時に出社するんだ！',\n",
       "  '今日は内蔵系を喰らふ。',\n",
       "  'ジギョつくの資料がまだできてない・・・提出期限の延長求む！',\n",
       "  '社長は酔っ払ってると思われる(笑)',\n",
       "  '資料をシコシコ作成中。資料作成はじめはやはりホルモンを聴きながらテンション上げる。',\n",
       "  '「枯れない花はないが、咲かない花はある。世の中は決定的に不公平だ」僕はいいコトバだと思ってます。',\n",
       "  'アボカドを短冊状に切り、醤油にワサビ、少々のごまドレッシングをといたタレと納豆を合えて食べると死ぬほどうまいです。多分、ご飯にかけたら最高です・・・が、今はダイエット中のため禁止。',\n",
       "  '2年後くらいに「できる男は作ってる！？働く男のパワー飯」という料理本を書きたいなう。',\n",
       "  'あ、あと1人で1800人になりそうです。さぁ、1800人目は誰だ！？',\n",
       "  'ここ2日でフォロワーが200人増えとるな・・・スゴ。フォロワー増にもティッピングポイントってあるんだろうな。',\n",
       "  '資料のテンションが低い。音楽が悪いのか？やはりPerfumeか？',\n",
       "  '社長と飲みに行くことになりました。日程調整中★',\n",
       "  'GmailがTwitterのフォロー連絡でうもれてる・・・',\n",
       "  '女性にとってやりがいのある職場創りをシンケンに考える。考える。',\n",
       "  'パルコに行ったら、すっかりバレンタインだった。',\n",
       "  '業界をポジティブにする買収とネガティブにする買収があるんだ。',\n",
       "  'いい飲みだった(よね？)',\n",
       "  'ある側面から言えば、現役女子大生3人囲まれる会。言葉と切り口の怖さを感じつつ、きっとバズマンだったら勘違いするな(笑)',\n",
       "  'テイラーとか、ちゃんと読もう。',\n",
       "  'Twitterで議論するのは難しいなぁ。やり方をちゃんとしないと。余計なコトバを吐いちゃうから。',\n",
       "  '鉄板焼きの雲丹ご飯は何ゆえあんなにうまいのだろう。。。',\n",
       "  '300人オーバーでフォローすると、「TLを追う」なんてそもそも不可能。セレンディップに割り切るしかない。でもそれが正しい。と思う。でも個人的にはここら辺が限度だな、うん。',\n",
       "  '「経営とは、人を通じて物事を達成する技なり」「経営とは、平凡な人に非凡な仕事をさせる技なり」',\n",
       "  '腹筋100回くらいはつらくなくなってきた。',\n",
       "  '「人に魚を与えれば1日生かすことができる。だが、魚の釣り方を教えれば、一生いかすことができる。」',\n",
       "  'ダイエットの話をする機会が増えたが（笑）、よく「でもそんな方法だとリバウンドしない？」とよく言われる。たぶんそれはダイエットを短期で捉えているからであり、習慣を変えようとしない態度からの発言で、たぶんこの人はダイエットに成功することはない。たぶん。',\n",
       "  'Twitterやってるとどうしても「暇なの？」的なことを言われる。「いやいやいや」と言い訳はいくらでも思いつくが（というか言い訳ではないが）、そう思われるということが大事なところなんだと、大人になろう。',\n",
       "  'リプライがmixiでいう足跡返し的な感じになるとしんどいな。でもあると思います。',\n",
       "  '今日はインタラ塾行けないかも…',\n",
       "  '20代広告業界飲み、という変に閉鎖的な飲み会やったら人来るかしら？',\n",
       "  'ジギョつく、ウチの部署から10個は出す。',\n",
       "  '【業務連絡：20代広告系飲み会】①飲み会の名前を募集、②幹事（ワタクシアドマン＋3名ほど）募集中。',\n",
       "  '２０代で飲むと、給料日前とかの日取りはアウトだな。',\n",
       "  'そういえばさっき７７７の福田さんがマークシティにいらっしゃいました。',\n",
       "  '今からジギョつく用の提出シートを鬼のように書く。案はたくさんあるので、書けるところまで・・・',\n",
       "  'ジギョつく1案目完成！さて2案目！',\n",
       "  '今からインタラ塾飲み会に参加するのは無謀なので、残念ですが控えます・・・',\n",
       "  'ブログのアクセスが久々に4000を超えてる＠アナリティクス。今日は完全にTwitter効果。',\n",
       "  'そして六本木到着。その後インタラ塾に駆けつけられるか？？',\n",
       "  'あと1名でフォロワーが1900人☆',\n",
       "  'うーん、オレも新人賞取りたかったなぁ～。',\n",
       "  'ワイデンに行った次の日は体重が減る。',\n",
       "  'そういえば、何気に昨日伊藤さんと初対面。今後とも宜しくお願いします★',\n",
       "  '誰かと一緒に提案するとき、僕以外のメンバーがしゃべっていて「その通り！」というと思うときは、深くうなづくようにしている。',\n",
       "  'ここんとこ、フォロワーが１日１００人ずつくらい増えてる・・・',\n",
       "  'マイスウィートオフィス（トイレ大）に篭って考え事したいのだが、あいにく現在満室状態。。。',\n",
       "  '「渡邊大介 サイバー」という検索からの流入が多く、ちょっと怖い・・・',\n",
       "  'ネット系、意外と少ない？',\n",
       "  'ストリームとアーカイブ。ビビりの時代。',\n",
       "  'No Implementation,No Creativity.',\n",
       "  '最近、会社に帰るとメールではなく、Hootsuiteを開く自分がいる。',\n",
       "  '今月はタクシーが少ない。これもウォーキング効果。',\n",
       "  '髪の毛をきってくる\\u3000。',\n",
       "  'バズマンがウザイこと行ってるがシカトしよ。',\n",
       "  '明日のメタバースカンファレンスいけなそうだ…',\n",
       "  '裏で動いて決まる、ということは世の中いくらでもある。',\n",
       "  'モモちゃんのトピックスが絶妙にウザイｗ',\n",
       "  '昨日くらいからまた、面接を受けにたくさんの学生が来ている。この中から一緒に働く仲間ができると思うと面白い。ということで、今からアポ。',\n",
       "  '「企画でテーブルが揺れる時がある」そんなんが日常茶飯事な組織を作る。',\n",
       "  'うむ、いいミーティングができた。もちろんYUREX使わずに(笑)',\n",
       "  'Hootsuiteばっかやってると、Twitterのバナーを見なくなるので、新しい企業アカウントに気づきにくくなる。',\n",
       "  '今日、備前がトピックス2件送ってる。たぶんあいつ、仕事してないｗｗ',\n",
       "  'TwitterってRead Onlyなユーザーて少ないと思うんだけど、どうなんだろ？ブログは結構いる。',\n",
       "  '丸くなるな★星になれ！',\n",
       "  '社長からTwitterやりすぎてきなツッコミを受けたｗ\\u3000仕事はしてます★',\n",
       "  'これはジギョつく、落ちたパターンか？？？',\n",
       "  'ブログへのHootsuiteからの流入が多くなっている。',\n",
       "  'あ、ジギョつく通ったー★\\u30005案出して1案。うーん、次はもうちょっと確度上げたい。が、一旦最終プレゼンがんばろ。',\n",
       "  '金曜のこの時間にメディアニュースが結構来るんだが・・・',\n",
       "  '次回はジギョつく案をツイッターで募集するとか・・・だめか。',\n",
       "  '来月は弊事業部、キャパいっぱいのため、私、現場でバリバリやらせていただきます。お仕事お待ちしております★',\n",
       "  'ちなみに今年の運勢的には、2月、4月、10月が調子いいようです、私。',\n",
       "  'あ、 タイムラインが寝た。',\n",
       "  '結局、歩いて帰りました★',\n",
       "  'うーん。若干ネガティブな感じ。二年前のようだ。',\n",
       "  '誰かがどこかでad★manを呼んでいる…',\n",
       "  'アボカド納豆とシジミ味噌汁。至福。',\n",
       "  'あ、 フォロワーさんが2000人を越えてる!!あざーっす。',\n",
       "  '今更ながらTHIS IS ITをDVD買って観てる。ふぉう。',\n",
       "  'ラクーアに行くらしい。',\n",
       "  'いろんなところを歩くと、道は立体的であることに気づく。アハ体験。',\n",
       "  'ラクーアに行こうといていたが、ピンパンを着用していて危なかった…',\n",
       "  '南北線なう。やたら車内で自分撮りしている女性に、どう反応したらいいかわからないなう。',\n",
       "  '飯田橋なう。前の女子中学生がアイプチしており、その威力に改めて驚かされるなう。',\n",
       "  'スパラクーア到着なう。リア充なう。',\n",
       "  'ウォーキング続けてると、デトックス効率よくなるの巻。',\n",
       "  '見ず知らずの若者と百度のサウナで根比べ。気づいたら20分経過しており、勝負には勝ったがフラフラなう。',\n",
       "  'クッキーに遭遇した★',\n",
       "  'さっき代官山で食べたんだが、塩昆布卵かけご飯がヤバイ。小野田商店のスペたま丼に匹敵する。',\n",
       "  'オイラ、夜のプロテインは向いてないや。朝にしよ。',\n",
       "  '前にも書いたが、挨拶は基本だと思う（と、無礼者のオイラが言う）。',\n",
       "  '今日はなんかお腹が痛いです…★',\n",
       "  'ほんっとにお腹痛い件。',\n",
       "  '上司と喋らなくなるのは良くない。透明性が一気に濁る。そう、濁った感じ。',\n",
       "  '今日からコーヒーはMAX２杯まで。ジュースは基本飲まず、ベース水で行きます。',\n",
       "  'コンテンツがあるところに人があるまり会話していると言うのは、極めてお茶の間的。',\n",
       "  '今更だけど、内定者バイトは最高のアピールの場。母数が少ないからいろんな人に見てもらえる。だからちょっと仕事になれよう、くらいでやると損すると思う。いろいろ。できれば「あの子はできる！」とか「ウチの部署で働いて欲しい！」って思わせて終わってもらいたい。',\n",
       "  '本日2本目の「日田天領水」。意外とうまい！と思い込んで飲む。思い込みが大事。水500mlに158円出すさ・・・',\n",
       "  'さて、出かけます。行ってきます。',\n",
       "  '昔オヤジに「飲み会に呼ぶのと呼ばれるのでは天地の差がある。幹事は買ってでもしろ！」と言われたことを思い出した。何の差かはわからんが…',\n",
       "  '反響がなかったので今一度つぶやくけど(しつこい)、 塩昆布TKGは至高の味である。ぜひ今夜！',\n",
       "  '本日で卒業の内定者バイトsacra。容姿端麗、頭脳明晰、温厚篤実。とっても素敵なやつでした。いったんお疲れ様でした。',\n",
       "  'そろそろデッカイ波（いい意味で）がくるかなぁ、と思ったら、今日来た。糧にしよう。',\n",
       "  'あ、言ってるそばから2月パンパンムード。',\n",
       "  'ソーシャルメディアマーケティング、を戦争とするのもちょっと僕の感覚と違う。戦うもんではない。',\n",
       "  '「へー、アドマンってTwitterやってるんだ」と同期に言われ、自分が少し調子にのっていたことを反省した2/2。',\n",
       "  'ウチの母ちゃんは「公文式」の教室を持っているんだが、ぜひともTwitterをやらせたい。企画書を提出しよう★',\n",
       "  '賢明（SMART）に考えてから、一所懸命（HARD）に努力すること。また賢明に努力しながら、一所懸命に考えること。',\n",
       "  '人のパソコンを覗くのはよい趣味じゃないよね。殴るよ（念のため、嘘です）。',\n",
       "  'マークシティ４Fのサンクスが2/5～2/17まで改修工事で営業しないなんて、オイラは認めてないんだからね！',\n",
       "  '飲むものが「コントレックス」しかない状況だと、「コントレックス」もうまく感じる。',\n",
       "  'ダイエットサプリを輸入してみたｗ',\n",
       "  '今日、コーヒー飲まなかった、オレ。偉い！',\n",
       "  'そういや、アメブロの「読者登録数」をTwitterのフォロワー数が上回った。特に違和感はなし。',\n",
       "  '雪の中帰る。まだ降ってる？',\n",
       "  '営業チックな仕事が1件増えそうだ。キライじゃないけど★',\n",
       "  '3/12は僕がダメなことが判明。',\n",
       "  '幹事用にMLを作成したので、確認してみてくださいませ！',\n",
       "  'カップのなめこ汁がうますぎる件。これはハマリそう。',\n",
       "  'さて、今から40分歩く。',\n",
       "  '最近冷たい上司、演じ中★',\n",
       "  'トイレ大が満室。みんな好きね。',\n",
       "  'livedoorニュースが見れない？',\n",
       "  '長丁場アポなう。休憩中なう。',\n",
       "  'ロングロングミーティング終了。今から帰ります…',\n",
       "  '取引先のBARでワインを飲み、頭が痛い。赤ワインだけはダメ・・・',\n",
       "  'なめこ汁なう。じるなう。',\n",
       "  'あ、イケダノリユキ氏オンステージまであと40分。',\n",
       "  '本日トイレ（大）に入りすぎて、ﾋﾘﾋﾘするなう。',\n",
       "  '体重がなかなか減らなくなったが、体脂肪率はガンガン減ってきてる今日この頃。',\n",
       "  '今日はお腹痛くない。なう。',\n",
       "  'クライアントからも「痩せましたね」と言われた。こういうコトバはダイエットに一番効くサプリメント。',\n",
       "  'コーヒーを三日間くらい抜いたら、中毒性が抜けてきた。人間の本質は「慣れ」だと思う今日この頃。',\n",
       "  'THEテレビ局人に圧倒された1時間ｗ',\n",
       "  '「ビジネスブログをやりましょう」ってレベルから早く脱却してくれないと。ホント。',\n",
       "  '新人賞は獲らせるもんでも、仕立て上げるもんでもない。獲るべきやつがとればいい。上司は余計なことをしないこと。',\n",
       "  '「嘘ついてない？」って詰めるのは、詰めるほうも結構しんどい。',\n",
       "  'そういうことやってると、痛い目見ると思うな～',\n",
       "  '情が湧いちゃうから、人事向いてないな、オレ。',\n",
       "  '「無茶ぶられ力」を磨かなきゃと思うアポでした。',\n",
       "  'お昼後のこの時間、例によってトイレ（大）は満室。お腹いっぱいになり眠くなるのはわかるが、トイレの中から聞こえてくる寝息に、どうしようもない憤りを感じるなう。',\n",
       "  'あともうちょいで、UCCのやつに便乗して、GEORGIAとかBOSSのbotも出てくんだろうな。',\n",
       "  'でもこういうのは、良くないよ。',\n",
       "  '就活生を見て、「絶対この娘、普段チャラい」とか予想するのが楽しい。',\n",
       "  '待ち時間とツイッターは相性よし。',\n",
       "  '今日の夜はU-30広告系飲み会(仮)幹事会です。',\n",
       "  'ハイパーつぶやきストへの道 講座。',\n",
       "  'まるでアレが水のようだ。',\n",
       "  'この際、アメーバなうのダミーアカウントについても触れて欲しい。',\n",
       "  '人間っぽさ。人間らしさ。人間としての・・・みたいな。',\n",
       "  '【緊急連絡】U-30飲み会幹事の皆さん、わけあって場所変更です。ML確認してください！',\n",
       "  '自分のつぶやき総数が16,535に達していることを確認し、若干萎えた。。。',\n",
       "  'トピックスメールは同じ人間が続けて打つと価値が薄まる（社内）。',\n",
       "  '今日はアポ2件あったのに、7回トイレ（大）に篭りました。たぶん体重減ってるはず。。。',\n",
       "  '会社からワイデンまで歩いたら、30分で着くことが今判明。今度から歩こう♪',\n",
       "  '結局、渋谷から六本木まで歩き、六本木から家まで歩いて帰って来ました♪ 万歩計は二万五千歩を記録。',\n",
       "  '住宅展示場で料理教室。ハードルを下げる。',\n",
       "  'オリアンティってギターうまいか？',\n",
       "  '僕が言うのもなんですが、中目黒で美味しいお店を教えてください。僕が知らなそうなお店を・・・',\n",
       "  '今日は中目黒kijimaに行く。',\n",
       "  'シェイプアップベルトが欲しい。お腹ブルブルするやつ。',\n",
       "  '信号機の青は横型だと向かって左、縦型だと下。意外とわからない。',\n",
       "  '洗濯用品は白と青が多い。',\n",
       "  'そう言えば、松岡さんに千円返してない。',\n",
       "  '目黒警察でトイレを借りる。意外と優しい。',\n",
       "  '人生はプラクティス。',\n",
       "  'マスク、帽子、グラサンかけて「愛され女になる方法」的な本を読んでいる女性。',\n",
       "  '白状すると、さっき知らない人に挨拶した。',\n",
       "  'だれですかー？僕の椅子に座ったの。座って良いから、位置とか傾斜とか元に直してよね。',\n",
       "  'てか絶対座った奴、なんかこぼしやがったな？下濡れてんだけど・・・怒',\n",
       "  'コメントを控えたくない。',\n",
       "  '「負の感情」はものすごいパワーを持っているが、使いすぎると「顔」に出る。',\n",
       "  '久々にコーヒーが飲みたくなったので・・・とはいえアレなので、「豆乳飲料\\u3000麦芽コーヒー」で妥協する。',\n",
       "  '結構弊社、席替えがあるのだが、その際に思うのは、どこの席になってもすぐその人がその席であることを認知される人と、そうでない人、とがいることである。',\n",
       "  '「よくTwitterでつぶやいてますよね」と言われるが、裏にだいたい「暇なんですね」ってのが見え隠れしていることには気づいているからね。とはいえ、君より働いてるからね！とかは言い返したい。',\n",
       "  'エスカレーターは、右を空ける感じでお願いします＠東京。',\n",
       "  'てか、オフィスの湿気がスゴすぎて、本が痛んでる件。',\n",
       "  'あ、経費精算しなきゃ。',\n",
       "  '「Twitterって平均すると100字くらいじゃん？5000ツイートすれば、50万字書いたことになる。新書くらい楽勝で書けるよ。」と言っている人がいたのだが、もちろん負に落ちるわけがない。',\n",
       "  '明日はスタッフ共有会でます。',\n",
       "  '最近YouTubeに、発売前のジャンプの原稿が駄々漏れしてるが・・・あれは・・・',\n",
       "  'ie 青葉台1*16',\n",
       "  'フラットでフリーであるが故に、Twitterにおける人間関係や言動、影響力などはもちろん「平等」ではないと思う。当たり前だけど。',\n",
       "  '作ってもらったカニの味噌汁が激うまい。',\n",
       "  'ソーシャルメディアで求められるのは、ぶっちゃけ社交的、社会的スキル。',\n",
       "  'どうやら我輩は大量の霊を引き寄せる体質らしく、現在、いるらしい。',\n",
       "  '銀座線出口で徳力さんとすれ違った。が、声かけられず…',\n",
       "  'いやー、これは大変なことになりそうだ。死ぬ気でがんばろ。死なないけど。',\n",
       "  '父「富と名声で幸せは買えない」\\u3000息子「それって試したことあるの？」',\n",
       "  'スパムコメントがうざいな。',\n",
       "  'TwitterのDMって、授業中に紙に書いて回すメッセージに似ている部分がある。',\n",
       "  '「それは難しいっすね」って言われたら一歩前進。',\n",
       "  'あ、幹事会の議事録送ってないや。',\n",
       "  '業界の大先輩との飲み会なう。帰っていろいろ考えてよ',\n",
       "  'バースデイの亀田特集が面白い。',\n",
       "  '出社なう。今日は途中まで徒歩。',\n",
       "  '外出が多すぎて、学生からのOB訪問とかをリスケしまくってる件。申し訳ない。',\n",
       "  '慣れないクライアントMTGは頭が汗だくになる。まずは背景、時系列、共通言語を理解する。',\n",
       "  '今日はガシッと痩せる気がする。68.9キロまでいけば、開始から約一ヶ月半で10キロの減量に成功したことになる♪',\n",
       "  '一駅圏内のアポなら歩く。 時間は10分も変わらないし、運動になるし、いろいろ考えられる。',\n",
       "  '記憶力がいい。あと参照力がある。',\n",
       "  'ふう、ようやく終了。今から帰社しまーす。',\n",
       "  'こういうのはハッシュじゃないな。',\n",
       "  '幸せと祝福の伝播。こういうツイッターはいいなぁ。(シラフ)',\n",
       "  'auお留守番サービスめ・・・',\n",
       "  'メディア活用の資産化。',\n",
       "  'カップ春雨に水をなみなみ注いだ俺。',\n",
       "  '今から銀座でDの方と飲み会。',\n",
       "  'H金さんが面白すぎます♪',\n",
       "  '終了っす。素直に楽しませて頂きました。まだまだ頂上は遠い。楽しいね。',\n",
       "  '代官山の福躍で締め完了。眠ひ',\n",
       "  '昨日、恥ずかしながら銀座で道に迷ったのだが（行き先に対して）、人に道を聞こうと声をかけたら最初の４人にスルーされた。Tokyoは冷たいなぁ・・・大阪は１パツで教えてくれたのに。',\n",
       "  '「勉強会をやります」というのはいいんだが、主催者は「何をやるのか」っていうのを「なんでやるのか」「どうやるのか」「だれがやるのか」ってところとリンクして考えないといけない。「何」だけ単純に伝えるなら、もっと良い方法がある（と思う）。',\n",
       "  '僕の同年代（２０代後半の人間）が、最近「最近の新卒ってありえないよね」的な会話をし始めてる。「最近の若者は・・・」というギリシャ時代から伝わる「年を取った証」の片鱗が随所で見え始めている。',\n",
       "  '今日はコーヒー解禁日に制定ｗ',\n",
       "  'Google Buzzをシコシコシコシコ。',\n",
       "  'ネイルをガッツリもられている女性がキーボードを叩くと、カチャカチャカチャカチャうるさいんだが、なんだか嫌いじゃない自分がいる。',\n",
       "  'サ○モトコ○ゾウのケツがプリプリしているのを見て、改めてダイエットへの決意を。ダイエットを初めてからただいま9.9キロ減量に成功。折り返し点突破。',\n",
       "  '昨日、採用の受付をやったんだけど、受付時の挨拶や目線の配り方、姿勢、心配りはとても目立。そこで評点つけてないと思うけど、とても評価が分かれる瞬間であった。',\n",
       "  '今から三時間、マン喫で集中勉強&思考タイム。こういう何もない空間が会社に欲しい。',\n",
       "  '最近会計の勉強がオモロイ。学生時代に会計士を目指して半年くらい実は勉強したんだけど、その時はつまんなくなって辞めちゃったのよね。もったいなかったな。',\n",
       "  '最近自動ドアとかトイレのエアタオルの反応が鈍いんだよね。人間として認められてない気分。',\n",
       "  'ソーシャルメディアマーケについて書かれた本を一般ユーザーが読んで嫌悪感を持つようじゃいけない。マーケターはこう攻めてくるのか(なんて考える人はいないけど)なんて思われるようではそもそもソーシャルではない。',\n",
       "  '予算がないから知恵を絞るのと、単に低予算、あるいはフリーでやるのとでは雲泥の差。SMMに関する勘違いは結構ここにある気がする。代理店側もいけないんだけど。',\n",
       "  '休日ってフォロワーが増える気がするのは僕だけ？',\n",
       "  '最近「アチシ負けない！」ってマインドが結構強い。',\n",
       "  'なんかピーピーなってるが、何が名ってるのかが不明。',\n",
       "  'めっちゃGoogleの検索結果にBuzzでるなぁ～。',\n",
       "  '「有名税」ってコトバは結構タブーだな。慰めにはなるけど、自分の行為や言動を振り返らなくなる（ジブン、まだまだ無名っすけどｗ。',\n",
       "  '筋金入りの「東京ウォーカー」な僕ですが、雨の日は歩きたくない。',\n",
       "  'ソーシャルメディアは場であって、媒体と捉えてしまうといろいろ良くない。じゃあ、メディアじゃないじゃん、みたいなツッコミは要りません★',\n",
       "  '来週のジャンプ、史上最高にワンピースで泣く。',\n",
       "  '雨やんでないじゃん…',\n",
       "  '使うコトバを変えて、意識と思考を変える。',\n",
       "  'オンラインって、なう的なコトバになる気がする。',\n",
       "  'いつ気づいてくれるかな。',\n",
       "  'ぶっ続け三時間ミーティング終了→帰社。',\n",
       "  'とはいえ、サクランボ♪',\n",
       "  'さくら咲く～★ とはいえ、サクランボ♪',\n",
       "  'オサムもサクランボ♪',\n",
       "  'カラオケに行きたい。',\n",
       "  'カラオケ行けなかった！ジダンダ',\n",
       "  '雪が降ってまスノー★',\n",
       "  '「人生は初のスタンディングオベーションはZEDでした」(事実)',\n",
       "  '顔に生気がない。大丈夫か？',\n",
       "  'そういえば最近、ちょっと一時期よりARGというコトバを聞かなくなった気がする。ちょっとだけ。',\n",
       "  'ジョーダンじゃなーいわよーう！',\n",
       "  '大人エレベーターに子供店長。そろそろキミマロ復活の予感。',\n",
       "  '事業プレゼン３分・・・ぶっちゃけスライド１枚。それとも作り込むか、あえて・・・悩む。',\n",
       "  'ジギョつく用のプレゼン資料を３０枚作った。これを5/1くらいまで圧縮する。本気とかいてマヂ。',\n",
       "  'Broadcasting Myself.',\n",
       "  '背景説明だけで、余裕で3分行くな。やばし。',\n",
       "  'デザイナーが欲しい。',\n",
       "  'Google Buzzman',\n",
       "  'キャッシュバックがハッシュタグに見えてくる今日この頃。',\n",
       "  '無言RTの理由を聞いてはいけないｗ',\n",
       "  '本日はよっちゃん さんのお誕生日です！',\n",
       "  '母にTwitterを。公文の教室をやってるので、企画考える。',\n",
       "  '内藤さんのジギョつく説明会資料が面白かった。たぶんこの資料をもとに、こういう話をしてるんだろうな、と想像しながら読む。',\n",
       "  'ゴーーーーーーーーーーーーーーーーーーーール！',\n",
       "  'なんてこった、PKや・・・楢崎がんばれ！',\n",
       "  'いやぁ・・・2対1・・・',\n",
       "  'レッドカードぉぉぉ！馬鹿！',\n",
       "  '個人的には、トゥーリオはずっと認めてない。俺に認められなくても何もアレだが・・・',\n",
       "  'またレッドカード＠韓国。',\n",
       "  '高橋大輔には似てないと思う。 アレか？二人目の妄想癖か(笑)',\n",
       "  'バイラルディレクター。',\n",
       "  '営業じゃなくなってから、アポから帰ってきた際にメールを見るのがちょっとだけ怖くなくなった（笑）。別の怖さがあるけど。',\n",
       "  '【急募】新しいパーソナルサイト「アドマン.TV」のデザイナー募集中★ お礼は超うまい鉄板焼きでお願いします。',\n",
       "  '突如会食に呼ばれたので、このMTGをあと１０分で終わらせる。',\n",
       "  '皆さん、お疲れ様でした！',\n",
       "  ...]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937f97122200431192eeabe77086087e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6887 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from src.my_project.dataset import preprocess_for_Trainer\n",
    "# tokenizerの定義\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# データセットの前処理\n",
    "add_data = preprocess_for_Trainer(add_dataset, tokenizer, max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['texts', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 6887\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction = trainer.predict(add_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2034, 0.5783],\n",
       "        [0.1482, 0.6651],\n",
       "        [0.5333, 0.4985],\n",
       "        ...,\n",
       "        [0.4281, 0.6999],\n",
       "        [0.1768, 0.6997],\n",
       "        [0.6294, 0.5123]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.from_numpy(prediction.predictions)\n",
    "predictions_proba = torch.sigmoid(logits)\n",
    "predictions_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2-6'></a>\n",
    "### 2.6 wandb終了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3-1'></a>\n",
    "## 3.1 Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 東北大BERT-v3\n",
    "MODEL_NAME = 'cl-tohoku/bert-base-japanese-v3'\n",
    "Classifier_model = ActClassifier(model_name = MODEL_NAME, num_labels=NUM_LABELS, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testデータと訓練に使用するデータに分割\n",
    "dataset, test_data = split_test_data(data=data, test_size=0.1, SEED=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Fold: 1-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Parameter 'fn_kwargs'={'tokenizer': BertJapaneseTokenizer(name_or_path='cl-tohoku/bert-base-japanese-v3', vocab_size=32768, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t3: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}, 'max_len': 128} of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458cce934aa2498f8d0a9371d573d2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3af7fe397e948ee9c3ba5221dc6b5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='1700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 119/1700 01:00 < 13:41, 1.93 it/s, Epoch 7/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.711200</td>\n",
       "      <td>0.710597</td>\n",
       "      <td>0.530303</td>\n",
       "      <td>0.480447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.669500</td>\n",
       "      <td>0.656976</td>\n",
       "      <td>0.656566</td>\n",
       "      <td>0.622222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.589500</td>\n",
       "      <td>0.600233</td>\n",
       "      <td>0.737374</td>\n",
       "      <td>0.686747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.487400</td>\n",
       "      <td>0.595034</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.683230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.371100</td>\n",
       "      <td>0.608887</td>\n",
       "      <td>0.747475</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.261100</td>\n",
       "      <td>0.649163</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>0.705263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>0.790321</td>\n",
       "      <td>0.732323</td>\n",
       "      <td>0.653595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1674e56e65974dd89c15643c78c8cc43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6291524171829224, 'eval_accuracy': 0.7090909090909091, 'eval_f1': 0.627906976744186, 'eval_runtime': 0.4645, 'eval_samples_per_second': 236.835, 'eval_steps_per_second': 6.459, 'epoch': 7.0}\n",
      "-----------------Fold: 2-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc588ec2835a48ae927fe608d022fc94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30823d11e64f49ba8d647713084778bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55cf633d411c4c49864be7a1a456b906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112318384564585, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='136' max='1700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 136/1700 01:06 < 12:56, 2.01 it/s, Epoch 8/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.748500</td>\n",
       "      <td>0.697589</td>\n",
       "      <td>0.525253</td>\n",
       "      <td>0.459770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.673200</td>\n",
       "      <td>0.660961</td>\n",
       "      <td>0.621212</td>\n",
       "      <td>0.452555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.604500</td>\n",
       "      <td>0.632580</td>\n",
       "      <td>0.661616</td>\n",
       "      <td>0.578616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.499600</td>\n",
       "      <td>0.634274</td>\n",
       "      <td>0.686869</td>\n",
       "      <td>0.602564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.391600</td>\n",
       "      <td>0.626672</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.274400</td>\n",
       "      <td>0.764754</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.592593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.159800</td>\n",
       "      <td>0.843573</td>\n",
       "      <td>0.671717</td>\n",
       "      <td>0.644809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>1.043405</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.565789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4fd5d207fd4b249b0788a5ef10a9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6080381870269775, 'eval_accuracy': 0.6545454545454545, 'eval_f1': 0.6346153846153846, 'eval_runtime': 0.463, 'eval_samples_per_second': 237.59, 'eval_steps_per_second': 6.48, 'epoch': 8.0}\n",
      "-----------------Fold: 3-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb38e9184d4f4b278d4e72a9b71bfb81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae25d9a31eb4800b0a91f74ef5bc3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d0b21e9ee64ee5bbb02c5bd0ae12b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112376167956326, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='1700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 119/1700 00:58 < 13:05, 2.01 it/s, Epoch 7/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.752400</td>\n",
       "      <td>0.707752</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.542056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.675500</td>\n",
       "      <td>0.686234</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.526882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.611900</td>\n",
       "      <td>0.622533</td>\n",
       "      <td>0.661616</td>\n",
       "      <td>0.659898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.505300</td>\n",
       "      <td>0.603069</td>\n",
       "      <td>0.686869</td>\n",
       "      <td>0.643678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.380500</td>\n",
       "      <td>0.607134</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.655172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.249300</td>\n",
       "      <td>0.783901</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.144600</td>\n",
       "      <td>0.766034</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>0.676768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29c183100c24eb8b1563411dbb0d793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5835622549057007, 'eval_accuracy': 0.6545454545454545, 'eval_f1': 0.6274509803921569, 'eval_runtime': 0.4784, 'eval_samples_per_second': 229.954, 'eval_steps_per_second': 6.271, 'epoch': 7.0}\n",
      "-----------------Fold: 4-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d9c7ba818a4f948301562f6024abc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763df49734774c2a9309369a7b8e9d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01d95929727470ab9d5c7de7dac1f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112243609709872, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='119' max='1700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 119/1700 00:59 < 13:23, 1.97 it/s, Epoch 7/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.757200</td>\n",
       "      <td>0.683052</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.552486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.669400</td>\n",
       "      <td>0.649150</td>\n",
       "      <td>0.626263</td>\n",
       "      <td>0.559524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.604800</td>\n",
       "      <td>0.617457</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.502700</td>\n",
       "      <td>0.605807</td>\n",
       "      <td>0.702020</td>\n",
       "      <td>0.654971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.391400</td>\n",
       "      <td>0.651602</td>\n",
       "      <td>0.671717</td>\n",
       "      <td>0.670051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.277700</td>\n",
       "      <td>0.683358</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>0.627907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.176800</td>\n",
       "      <td>0.763322</td>\n",
       "      <td>0.691919</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab85c7e7caff4c2ea257e69ebf5f0fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6545231342315674, 'eval_accuracy': 0.6363636363636364, 'eval_f1': 0.5348837209302325, 'eval_runtime': 0.4757, 'eval_samples_per_second': 231.235, 'eval_steps_per_second': 6.306, 'epoch': 7.0}\n",
      "-----------------Fold: 5-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df547fc78bc7451abb4c43782fe7afdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/792 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adfcc7f5defe4586830fb7a3406e3444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "881530753e6e4564b7f921b57d3cf239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112461228751473, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='136' max='1700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 136/1700 01:07 < 13:04, 1.99 it/s, Epoch 8/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.759300</td>\n",
       "      <td>0.687292</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.547486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.675700</td>\n",
       "      <td>0.639361</td>\n",
       "      <td>0.661616</td>\n",
       "      <td>0.524823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.617400</td>\n",
       "      <td>0.588679</td>\n",
       "      <td>0.702020</td>\n",
       "      <td>0.609272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>0.544966</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.674556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.437600</td>\n",
       "      <td>0.526422</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.708995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.333500</td>\n",
       "      <td>0.533907</td>\n",
       "      <td>0.762626</td>\n",
       "      <td>0.711656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.245500</td>\n",
       "      <td>0.537196</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.741176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.173100</td>\n",
       "      <td>0.545736</td>\n",
       "      <td>0.747475</td>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d151a9c16448c3a029165c792e3696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6337300539016724, 'eval_accuracy': 0.6545454545454545, 'eval_f1': 0.6041666666666666, 'eval_runtime': 0.4631, 'eval_samples_per_second': 237.555, 'eval_steps_per_second': 6.479, 'epoch': 8.0}\n"
     ]
    }
   ],
   "source": [
    "result = Classifier_model.cross_validation(dataset, test_data, MAX_LEN, NUM_EPOCHS, LEARNING_RATE, BATCH_SIZE, PATIENCE, NUM_FOLDS, output_dir, project_name='ActClassification_cross_validation_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'eval_loss': 0.6291524171829224,\n",
       "  'eval_accuracy': 0.7090909090909091,\n",
       "  'eval_f1': 0.627906976744186,\n",
       "  'eval_runtime': 0.4645,\n",
       "  'eval_samples_per_second': 236.835,\n",
       "  'eval_steps_per_second': 6.459,\n",
       "  'epoch': 7.0},\n",
       " {'eval_loss': 0.6080381870269775,\n",
       "  'eval_accuracy': 0.6545454545454545,\n",
       "  'eval_f1': 0.6346153846153846,\n",
       "  'eval_runtime': 0.463,\n",
       "  'eval_samples_per_second': 237.59,\n",
       "  'eval_steps_per_second': 6.48,\n",
       "  'epoch': 8.0},\n",
       " {'eval_loss': 0.5835622549057007,\n",
       "  'eval_accuracy': 0.6545454545454545,\n",
       "  'eval_f1': 0.6274509803921569,\n",
       "  'eval_runtime': 0.4784,\n",
       "  'eval_samples_per_second': 229.954,\n",
       "  'eval_steps_per_second': 6.271,\n",
       "  'epoch': 7.0},\n",
       " {'eval_loss': 0.6545231342315674,\n",
       "  'eval_accuracy': 0.6363636363636364,\n",
       "  'eval_f1': 0.5348837209302325,\n",
       "  'eval_runtime': 0.4757,\n",
       "  'eval_samples_per_second': 231.235,\n",
       "  'eval_steps_per_second': 6.306,\n",
       "  'epoch': 7.0},\n",
       " {'eval_loss': 0.6337300539016724,\n",
       "  'eval_accuracy': 0.6545454545454545,\n",
       "  'eval_f1': 0.6041666666666666,\n",
       "  'eval_runtime': 0.4631,\n",
       "  'eval_samples_per_second': 237.555,\n",
       "  'eval_steps_per_second': 6.479,\n",
       "  'epoch': 8.0}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.6618181818181819\n",
      "Average f1: 0.6058047458697253\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = sum(d['eval_accuracy'] for d in result)/len(result)\n",
    "average_f1 = sum(d['eval_f1'] for d in result)/len(result)\n",
    "print(\"Average accuracy:\", average_accuracy)\n",
    "print(\"Average f1:\", average_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
